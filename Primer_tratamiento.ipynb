{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cfbfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamiento Básico\n",
    "# proceso para reducir las bases \n",
    "# FAC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52181836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analizando datos para 2025 T2 ---\n",
      "Buscando archivo en: Data\\ENOE_dta\\ENOE_2025_2\\ENOE_SDEMT225.dta\n",
      "✅ Archivo cargado exitosamente. 423744 registros leídos.\n",
      "Calculando población estimada por edad y género...\n",
      "\n",
      "--- Resultados del Análisis ---\n",
      "Población estimada para 2025 T2 (primeros 20 resultados):\n",
      "    Edad  Género  Poblacion_Estimada\n",
      "0      0  Hombre            543800.0\n",
      "1      0   Mujer            482893.0\n",
      "2      1  Hombre            645797.0\n",
      "3      1   Mujer            663950.0\n",
      "4      2  Hombre            734343.0\n",
      "5      2   Mujer            668793.0\n",
      "6      3  Hombre            810301.0\n",
      "7      3   Mujer            731215.0\n",
      "8      4  Hombre            768016.0\n",
      "9      4   Mujer            804740.0\n",
      "10     5  Hombre            874860.0\n",
      "11     5   Mujer            880538.0\n",
      "12     6  Hombre            984654.0\n",
      "13     6   Mujer            926439.0\n",
      "14     7  Hombre           1008299.0\n",
      "15     7   Mujer            939588.0\n",
      "16     8  Hombre           1023076.0\n",
      "17     8   Mujer            992772.0\n",
      "18     9  Hombre           1022976.0\n",
      "19     9   Mujer           1077310.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def analizar_poblacion_por_edad_y_genero(year, quarter):\n",
    "    \"\"\"\n",
    "    Carga los microdatos sociodemográficos de la ENOE para un periodo específico\n",
    "    y calcula la población estimada agrupada por edad y género.\n",
    "\n",
    "    Args:\n",
    "        year (int): El año a analizar.\n",
    "        quarter (int): El trimestre a analizar (1-4).\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Un DataFrame con la población estimada por edad y género,\n",
    "                      o None si el archivo no se encuentra.\n",
    "    \"\"\"\n",
    "    print(f\"--- Analizando datos para {year} T{quarter} ---\")\n",
    "    \n",
    "    # --- 1. Construir la ruta del archivo ---\n",
    "    # Nota: Los nombres de archivo dentro del zip pueden variar y a menudo están en minúsculas.\n",
    "    # El patrón común es sdemt<trimestre><año de dos dígitos>.dta\n",
    "    file_format = 'dta'\n",
    "    year_short = str(year)[-2:] # Obtiene los últimos dos dígitos del año, ej: 25 para 2025\n",
    "    \n",
    "    # Construir el nombre del directorio y del archivo\n",
    "    dir_name = f\"ENOE_{year}_{quarter}\"\n",
    "    file_name = f\"ENOE_SDEMT{quarter}{year_short}.dta\" # ej. sdemt225.dta\n",
    "    \n",
    "    file_path = os.path.join(\"Data\", f\"ENOE_{file_format}\", dir_name, file_name)\n",
    "    \n",
    "    print(f\"Buscando archivo en: {file_path}\")\n",
    "\n",
    "    # --- 2. Cargar los datos ---\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ Error: No se encontró el archivo '{file_path}'.\")\n",
    "        print(\"   Verifica que la descarga se haya completado para este periodo.\")\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        # Usamos read_stata, que es muy rápido para archivos .dta\n",
    "        df = pd.read_stata(file_path, convert_categoricals = False)\n",
    "        print(f\"✅ Archivo cargado exitosamente. {len(df)} registros leídos.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error al leer el archivo Stata: {e}\")\n",
    "        return None\n",
    "\n",
    "    # --- 3. Preparación y limpieza de datos ---\n",
    "    # Asegurarse de que las columnas clave sean numéricas, manejando errores\n",
    "    columnas_a_convertir = ['fac_tri', 'eda', 'sex']\n",
    "    for col in columnas_a_convertir:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Eliminar filas donde la conversión falló o los datos son nulos\n",
    "    df.dropna(subset=columnas_a_convertir, inplace=True)\n",
    "    \n",
    "    # --- 4. Realizar el cálculo ---\n",
    "    print(\"Calculando población estimada por edad y género...\")\n",
    "    \n",
    "    # Agrupar por edad (eda) y sexo (sex), y sumar el factor de expansión (fac_tri)\n",
    "    poblacion = df.groupby(['eda', 'sex'])['fac_tri'].sum().reset_index()\n",
    "    \n",
    "    # --- 5. Mejorar la presentación ---\n",
    "    # Mapear los códigos de 'sex' a etiquetas de texto para mayor claridad\n",
    "    # Según el diccionario de datos de INEGI: 1 es Hombre, 2 es Mujer\n",
    "    poblacion['sex'] = poblacion['sex'].map({1: 'Hombre', 2: 'Mujer'})\n",
    "    \n",
    "    # Renombrar columnas para un reporte más claro\n",
    "    poblacion.rename(columns={\n",
    "        'eda': 'Edad',\n",
    "        'sex': 'Género',\n",
    "        'fac_tri': 'Poblacion_Estimada'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Convertir edad a entero para una mejor visualización\n",
    "    poblacion['Edad'] = poblacion['Edad'].astype(int)\n",
    "    \n",
    "    return poblacion\n",
    "\n",
    "# --- Ejecución del Script ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Define el año y trimestre que quieres analizar\n",
    "    # Puedes cambiar estos valores para analizar otros periodos\n",
    "    YEAR_A_ANALIZAR = 2025\n",
    "    QUARTER_A_ANALIZAR = 2\n",
    "    \n",
    "    # Llamar a la función principal\n",
    "    resultado_poblacion = analizar_poblacion_por_edad_y_genero(YEAR_A_ANALIZAR, QUARTER_A_ANALIZAR)\n",
    "    \n",
    "    # Imprimir los resultados si el análisis fue exitoso\n",
    "    if resultado_poblacion is not None:\n",
    "        print(\"\\n--- Resultados del Análisis ---\")\n",
    "        print(f\"Población estimada para {YEAR_A_ANALIZAR} T{QUARTER_A_ANALIZAR} (primeros 20 resultados):\")\n",
    "        # Usamos .to_string() para asegurar que se muestren todas las columnas bien alineadas\n",
    "        print(resultado_poblacion.head(20).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df83553a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando análisis para 2025 T2 ---\n",
      "Buscando archivo en: data\\ENOE_dta\\ENOE_2025_2\\ENOE_SDEMT225.dta\n",
      "✅ Archivo cargado exitosamente. 423744 registros leídos.\n",
      "\n",
      "--- Analizando Población por Edad y Género ---\n",
      "\n",
      "--- Resultados: Población por Edad y Género (primeros 20) ---\n",
      "    Edad  Género  Poblacion_Estimada\n",
      "0      0  Hombre            543800.0\n",
      "1      0   Mujer            482893.0\n",
      "2      1  Hombre            645797.0\n",
      "3      1   Mujer            663950.0\n",
      "4      2  Hombre            734343.0\n",
      "5      2   Mujer            668793.0\n",
      "6      3  Hombre            810301.0\n",
      "7      3   Mujer            731215.0\n",
      "8      4  Hombre            768016.0\n",
      "9      4   Mujer            804740.0\n",
      "10     5  Hombre            874860.0\n",
      "11     5   Mujer            880538.0\n",
      "12     6  Hombre            984654.0\n",
      "13     6   Mujer            926439.0\n",
      "14     7  Hombre           1008299.0\n",
      "15     7   Mujer            939588.0\n",
      "16     8  Hombre           1023076.0\n",
      "17     8   Mujer            992772.0\n",
      "18     9  Hombre           1022976.0\n",
      "19     9   Mujer           1077310.0\n",
      "\n",
      "--- Calculando Indicadores Ampliados ---\n",
      "\n",
      "--- Resultados: Indicadores Demográficos y Económicos ---\n",
      "1. Población Total Estimada: 0\n",
      "2. Total de Hombres: 0\n",
      "3. Total de Mujeres: 0\n",
      "4. PEA Hombres: 0\n",
      "5. PEA Mujeres: 0\n",
      "6. Ingreso Promedio Mensual (Mujer): $0.00\n",
      "7. Ingreso Promedio Mensual (Hombre): $0.00\n",
      "\n",
      "8. Ingreso Promedio Mensual por Estado:\n",
      "Empty DataFrame\n",
      "Columns: [r_def, loc, mun, est, est_d_tri, est_d_men, ageb, t_loc_tri, t_loc_men, cd_a, ent, con, upm, d_sem, n_pro_viv, v_sel, n_hog, h_mud, n_ent, per, n_ren, c_res, par_c, sex, eda, nac_dia, nac_mes, nac_anio, l_nac_c, cs_p12, cs_p13_1, cs_p13_2, cs_p14_c, cs_p15, cs_p16, cs_p17, n_hij, e_con, cs_p20a_1, cs_p20a_c, cs_p20b_1, cs_p20b_c, cs_p20c_1, cs_ad_mot, cs_p21_des, cs_ad_des, cs_nr_mot, cs_p23_des, cs_nr_ori, ur, zona, salario, fac_tri, fac_men, clase1, clase2, clase3, pos_ocu, seg_soc, rama, c_ocu11c, ing7c, dur9c, emple7c, medica5c, buscar5c, rama_est1, rama_est2, dur_est, ambito1, ambito2, tue1, tue2, tue3, busqueda, d_ant_lab, d_cexp_est, dur_des, sub_o, s_clasifi, remune2c, pre_asa, tip_con, dispo, nodispo, c_inac5c, pnea_est, niv_ins, eda5c, eda7c, eda12c, eda19c, hij5c, domestico, anios_esc, hrsocup, ingocup, ing_x_hrs, tpg_p8a, tcco, ...]\n",
      "Index: []\n",
      "\n",
      "9. Ingreso Promedio por Hora (Total): $0.00\n",
      "10. Ingreso Promedio por Hora (Mujer): $0.00\n",
      "    Ingreso Promedio por Hora (Hombre): $0.00\n",
      "\n",
      "11. Masa Salarial Total Mensual: $0.00\n",
      "\n",
      "12. Masa Salarial Mensual por Estado:\n",
      "Empty DataFrame\n",
      "Columns: [r_def, loc, mun, est, est_d_tri, est_d_men, ageb, t_loc_tri, t_loc_men, cd_a, ent, con, upm, d_sem, n_pro_viv, v_sel, n_hog, h_mud, n_ent, per, n_ren, c_res, par_c, sex, eda, nac_dia, nac_mes, nac_anio, l_nac_c, cs_p12, cs_p13_1, cs_p13_2, cs_p14_c, cs_p15, cs_p16, cs_p17, n_hij, e_con, cs_p20a_1, cs_p20a_c, cs_p20b_1, cs_p20b_c, cs_p20c_1, cs_ad_mot, cs_p21_des, cs_ad_des, cs_nr_mot, cs_p23_des, cs_nr_ori, ur, zona, salario, fac_tri, fac_men, clase1, clase2, clase3, pos_ocu, seg_soc, rama, c_ocu11c, ing7c, dur9c, emple7c, medica5c, buscar5c, rama_est1, rama_est2, dur_est, ambito1, ambito2, tue1, tue2, tue3, busqueda, d_ant_lab, d_cexp_est, dur_des, sub_o, s_clasifi, remune2c, pre_asa, tip_con, dispo, nodispo, c_inac5c, pnea_est, niv_ins, eda5c, eda7c, eda12c, eda19c, hij5c, domestico, anios_esc, hrsocup, ingocup, ing_x_hrs, tpg_p8a, tcco, ...]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\AppData\\Local\\Temp\\ipykernel_12592\\1490822636.py:80: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  resultados['ingreso_prom_mensual_estado'] = df_ocupada.groupby('ent_nombre').apply(\n",
      "C:\\Users\\rodri\\AppData\\Local\\Temp\\ipykernel_12592\\1490822636.py:95: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  resultados['masa_salarial_estado'] = df_ocupada.groupby('ent_nombre').apply(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def calcular_indicadores_ampliados(df):\n",
    "    \"\"\"\n",
    "    Calcula una serie de indicadores demográficos y económicos a partir de los datos de la ENOE.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): El DataFrame ya cargado y limpio.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Un diccionario con todos los indicadores calculados.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Calculando Indicadores Ampliados ---\")\n",
    "    \n",
    "    # --- Preparación y Filtros Base ---\n",
    "    # Asegurar que las columnas adicionales para el cálculo sean numéricas\n",
    "    columnas_numericas_adicionales = ['clase1', 'clase2', 'ingocup', 'ing_x_hrs', 'ent']\n",
    "    for col in columnas_numericas_adicionales:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # Filtro base: Entrevista completa ('0.0') y residente habitual o nuevo (1 o 3)\n",
    "    df_base = df[(df['r_def'] == '0.0') & (df['c_res'].isin([1, 3]))].copy()\n",
    "    \n",
    "    # Filtro para población de 15 años y más\n",
    "    df_15_y_mas = df_base[df_base['eda'].between(15, 98)].copy()\n",
    "    \n",
    "    # Filtro para población ocupada (para cálculos de ingreso)\n",
    "    df_ocupada = df_15_y_mas[df_15_y_mas['clase2'] == 1].copy()\n",
    "\n",
    "    # Diccionario para mapear códigos de entidad a nombres\n",
    "    entidades = {\n",
    "        1: 'Aguascalientes', 2: 'Baja California', 3: 'Baja California Sur', 4: 'Campeche',\n",
    "        5: 'Coahuila', 6: 'Colima', 7: 'Chiapas', 8: 'Chihuahua', 9: 'Ciudad de México',\n",
    "        10: 'Durango', 11: 'Guanajuato', 12: 'Guerrero', 13: 'Hidalgo', 14: 'Jalisco',\n",
    "        15: 'México', 16: 'Michoacán', 17: 'Morelos', 18: 'Nayarit', 19: 'Nuevo León',\n",
    "        20: 'Oaxaca', 21: 'Puebla', 22: 'Querétaro', 23: 'Quintana Roo', 24: 'San Luis Potosí',\n",
    "        25: 'Sinaloa', 26: 'Sonora', 27: 'Tabasco', 28: 'Tamaulipas', 29: 'Tlaxcala',\n",
    "        30: 'Veracruz', 31: 'Yucatán', 32: 'Zacatecas'\n",
    "    }\n",
    "    df_ocupada['ent_nombre'] = df_ocupada['ent'].map(entidades)\n",
    "\n",
    "\n",
    "    # --- Inicio de Cálculos ---\n",
    "    resultados = {}\n",
    "\n",
    "    # 1. Total de la población (suma de todos los factores de expansión)\n",
    "    resultados['total_poblacion'] = df_base['fac_tri'].sum()\n",
    "\n",
    "    # 2. Total de hombres\n",
    "    resultados['total_hombres'] = df_base[df_base['sex'] == 1]['fac_tri'].sum()\n",
    "\n",
    "    # 3. Total de mujeres\n",
    "    resultados['total_mujeres'] = df_base[df_base['sex'] == 2]['fac_tri'].sum()\n",
    "\n",
    "    # 4. PEA Hombres\n",
    "    df_pea = df_15_y_mas[df_15_y_mas['clase1'] == 1]\n",
    "    resultados['pea_hombres'] = df_pea[df_pea['sex'] == 1]['fac_tri'].sum()\n",
    "\n",
    "    # 5. PEA Mujeres\n",
    "    resultados['pea_mujeres'] = df_pea[df_pea['sex'] == 2]['fac_tri'].sum()\n",
    "\n",
    "    # Función para cálculo de promedio ponderado\n",
    "    def weighted_average(df, value_col, weight_col):\n",
    "        df_filtered = df.dropna(subset=[value_col, weight_col])\n",
    "        if df_filtered.empty:\n",
    "            return 0\n",
    "        return np.average(df_filtered[value_col], weights=df_filtered[weight_col])\n",
    "\n",
    "    # 6. Ingreso promedio mensual Mujer\n",
    "    df_ocup_mujer = df_ocupada[df_ocupada['sex'] == 2]\n",
    "    resultados['ingreso_prom_mensual_mujer'] = weighted_average(df_ocup_mujer, 'ingocup', 'fac_tri')\n",
    "\n",
    "    # 7. Ingreso promedio mensual Hombre\n",
    "    df_ocup_hombre = df_ocupada[df_ocupada['sex'] == 1]\n",
    "    resultados['ingreso_prom_mensual_hombre'] = weighted_average(df_ocup_hombre, 'ingocup', 'fac_tri')\n",
    "\n",
    "    # 8. Ingreso promedio mensual por estado\n",
    "    resultados['ingreso_prom_mensual_estado'] = df_ocupada.groupby('ent_nombre').apply(\n",
    "        lambda x: weighted_average(x, 'ingocup', 'fac_tri')\n",
    "    )\n",
    "\n",
    "    # 9. Ingreso por hora promedio\n",
    "    resultados['ingreso_prom_hora_total'] = weighted_average(df_ocupada, 'ing_x_hrs', 'fac_tri')\n",
    "    \n",
    "    # 10. Ingreso promedio por hora (Hombre y Mujer)\n",
    "    resultados['ingreso_prom_hora_mujer'] = weighted_average(df_ocup_mujer, 'ing_x_hrs', 'fac_tri')\n",
    "    resultados['ingreso_prom_hora_hombre'] = weighted_average(df_ocup_hombre, 'ing_x_hrs', 'fac_tri')\n",
    "\n",
    "    # 11. Masa salarial total\n",
    "    resultados['masa_salarial_total'] = (df_ocupada['ingocup'] * df_ocupada['fac_tri']).sum()\n",
    "\n",
    "    # 12. Masa salarial por Estado\n",
    "    resultados['masa_salarial_estado'] = df_ocupada.groupby('ent_nombre').apply(\n",
    "        lambda x: (x['ingocup'] * x['fac_tri']).sum()\n",
    "    )\n",
    "\n",
    "    return resultados\n",
    "\n",
    "def analizar_poblacion_por_edad_y_genero(df):\n",
    "    \"\"\"\n",
    "    Calcula la población estimada agrupada por edad y género.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Analizando Población por Edad y Género ---\")\n",
    "    \n",
    "    # Agrupar por edad (eda) y sexo (sex), y sumar el factor de expansión (fac_tri)\n",
    "    poblacion = df.groupby(['eda', 'sex'])['fac_tri'].sum().reset_index()\n",
    "    \n",
    "    # Mapear los códigos de 'sex' a etiquetas de texto\n",
    "    poblacion['sex'] = poblacion['sex'].map({1: 'Hombre', 2: 'Mujer'})\n",
    "    \n",
    "    # Renombrar columnas\n",
    "    poblacion.rename(columns={\n",
    "        'eda': 'Edad', 'sex': 'Género', 'fac_tri': 'Poblacion_Estimada'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    poblacion['Edad'] = poblacion['Edad'].astype(int)\n",
    "    return poblacion\n",
    "\n",
    "# --- Ejecución del Script ---\n",
    "if __name__ == \"__main__\":\n",
    "    YEAR_A_ANALIZAR = 2025\n",
    "    QUARTER_A_ANALIZAR = 2\n",
    "    \n",
    "    print(f\"--- Iniciando análisis para {YEAR_A_ANALIZAR} T{QUARTER_A_ANALIZAR} ---\")\n",
    "    \n",
    "    # --- 1. Carga de datos ---\n",
    "    file_format = 'dta'\n",
    "    year_short = str(YEAR_A_ANALIZAR)[-2:]\n",
    "    dir_name = f\"ENOE_{YEAR_A_ANALIZAR}_{QUARTER_A_ANALIZAR}\"\n",
    "    file_name = f\"ENOE_SDEMT{QUARTER_A_ANALIZAR}{year_short}.dta\"\n",
    "    file_path = os.path.join(\"data\", f\"ENOE_{file_format}\", dir_name, file_name)\n",
    "    \n",
    "    print(f\"Buscando archivo en: {file_path}\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ Error: No se encontró el archivo. Ejecuta el script de descarga primero.\")\n",
    "    else:\n",
    "        try:\n",
    "            df_enoe = pd.read_stata(file_path, convert_categoricals=False)\n",
    "            print(f\"✅ Archivo cargado exitosamente. {len(df_enoe)} registros leídos.\")\n",
    "            \n",
    "            # --- 2. Preparación general de datos ---\n",
    "            columnas_base = ['fac_tri', 'eda', 'sex', 'r_def', 'c_res']\n",
    "            for col in columnas_base:\n",
    "                df_enoe[col] = pd.to_numeric(df_enoe[col], errors='coerce') if col not in ['r_def'] else df_enoe[col]\n",
    "            df_enoe.dropna(subset=['fac_tri', 'eda', 'sex', 'c_res'], inplace=True)\n",
    "\n",
    "            # --- 3. Ejecutar análisis y mostrar resultados ---\n",
    "            \n",
    "            # Análisis por edad y género\n",
    "            poblacion_edad_genero = analizar_poblacion_por_edad_y_genero(df_enoe.copy())\n",
    "            if poblacion_edad_genero is not None:\n",
    "                print(\"\\n--- Resultados: Población por Edad y Género (primeros 20) ---\")\n",
    "                print(poblacion_edad_genero.head(20).to_string())\n",
    "\n",
    "            # Indicadores ampliados\n",
    "            indicadores = calcular_indicadores_ampliados(df_enoe.copy())\n",
    "            if indicadores:\n",
    "                print(\"\\n--- Resultados: Indicadores Demográficos y Económicos ---\")\n",
    "                print(f\"1. Población Total Estimada: {indicadores['total_poblacion']:,.0f}\")\n",
    "                print(f\"2. Total de Hombres: {indicadores['total_hombres']:,.0f}\")\n",
    "                print(f\"3. Total de Mujeres: {indicadores['total_mujeres']:,.0f}\")\n",
    "                print(f\"4. PEA Hombres: {indicadores['pea_hombres']:,.0f}\")\n",
    "                print(f\"5. PEA Mujeres: {indicadores['pea_mujeres']:,.0f}\")\n",
    "                print(f\"6. Ingreso Promedio Mensual (Mujer): ${indicadores['ingreso_prom_mensual_mujer']:,.2f}\")\n",
    "                print(f\"7. Ingreso Promedio Mensual (Hombre): ${indicadores['ingreso_prom_mensual_hombre']:,.2f}\")\n",
    "                print(\"\\n8. Ingreso Promedio Mensual por Estado:\")\n",
    "                print(indicadores['ingreso_prom_mensual_estado'].map('${:,.2f}'.format).to_string())\n",
    "                print(f\"\\n9. Ingreso Promedio por Hora (Total): ${indicadores['ingreso_prom_hora_total']:,.2f}\")\n",
    "                print(f\"10. Ingreso Promedio por Hora (Mujer): ${indicadores['ingreso_prom_hora_mujer']:,.2f}\")\n",
    "                print(f\"    Ingreso Promedio por Hora (Hombre): ${indicadores['ingreso_prom_hora_hombre']:,.2f}\")\n",
    "                print(f\"\\n11. Masa Salarial Total Mensual: ${indicadores['masa_salarial_total']:,.2f}\")\n",
    "                print(\"\\n12. Masa Salarial Mensual por Estado:\")\n",
    "                print(indicadores['masa_salarial_estado'].map('${:,.2f}'.format).to_string())\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Ocurrió un error durante el análisis: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc94e3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando análisis para 2025 T2 ---\n",
      "Buscando archivo en: data\\ENOE_dta\\ENOE_2025_2\\ENOE_SDEMT225.dta\n",
      "✅ Archivo cargado exitosamente. 423744 registros leídos.\n",
      "\n",
      "--- Iniciando Cálculos de Indicadores ---\n",
      "\n",
      "--- Resultados: Población General ---\n",
      "1. Población Total Estimada: 130,575,786\n",
      "2. Total de Hombres: 62,260,360\n",
      "3. Total de Mujeres: 68,315,426\n",
      "4. PEA Hombres: 36,046,346\n",
      "5. PEA Mujeres: 25,018,659\n",
      "6. Ingreso Promedio Mensual (Mujer): $5,066.40\n",
      "7. Ingreso Promedio Mensual (Hombre): $6,341.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\AppData\\Local\\Temp\\ipykernel_12592\\538922952.py:86: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  ing_prom_estado = df_ocupada.groupby('ent_nombre').apply(lambda x: weighted_average(x, 'ingocup', 'fac_tri'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8. Ingreso Promedio Mensual por Estado:\n",
      "ent_nombre\n",
      "Aguascalientes          $5,160.97\n",
      "Baja California         $7,281.14\n",
      "Baja California Sur    $11,825.56\n",
      "Campeche                $8,138.65\n",
      "Chiapas                 $5,340.33\n",
      "Chihuahua               $8,440.37\n",
      "Ciudad de México        $5,720.30\n",
      "Coahuila                $9,338.23\n",
      "Colima                  $7,383.05\n",
      "Durango                 $7,485.46\n",
      "Guanajuato              $4,647.14\n",
      "Guerrero                $4,929.68\n",
      "Hidalgo                 $5,761.37\n",
      "Jalisco                 $5,215.58\n",
      "Michoacán               $6,155.89\n",
      "Morelos                 $2,937.55\n",
      "México                  $3,288.29\n",
      "Nayarit                 $8,751.47\n",
      "Nuevo León              $8,585.35\n",
      "Oaxaca                  $3,985.54\n",
      "Puebla                  $4,665.10\n",
      "Querétaro               $3,849.23\n",
      "Quintana Roo            $8,347.20\n",
      "San Luis Potosí         $4,713.56\n",
      "Sinaloa                 $8,917.37\n",
      "Sonora                  $6,350.36\n",
      "Tabasco                 $6,428.02\n",
      "Tamaulipas              $8,681.59\n",
      "Tlaxcala                $5,005.25\n",
      "Veracruz                $5,388.55\n",
      "Yucatán                 $7,883.56\n",
      "Zacatecas               $5,542.92\n",
      "\n",
      "9. Ingreso Promedio por Hora (Total): $36.47\n",
      "10. Ingreso Promedio por Hora (Mujer): $36.40\n",
      "    Ingreso Promedio por Hora (Hombre): $36.52\n",
      "\n",
      "11. Masa Salarial Total Mensual: $345,916,756,497.00\n",
      "\n",
      "12. Masa Salarial Mensual por Estado:\n",
      "ent_nombre\n",
      "Aguascalientes          $3,365,634,297.00\n",
      "Baja California        $12,736,049,332.00\n",
      "Baja California Sur     $5,276,092,743.00\n",
      "Campeche                $3,446,156,731.00\n",
      "Chiapas                $11,858,005,757.00\n",
      "Chihuahua              $15,704,779,938.00\n",
      "Ciudad de México       $28,262,717,916.00\n",
      "Coahuila               $14,581,287,491.00\n",
      "Colima                  $2,706,345,563.00\n",
      "Durango                 $6,441,621,286.00\n",
      "Guanajuato             $13,245,859,110.00\n",
      "Guerrero                $7,430,237,995.00\n",
      "Hidalgo                 $8,394,381,734.00\n",
      "Jalisco                $20,210,029,459.00\n",
      "Michoacán              $13,905,428,133.00\n",
      "Morelos                 $2,484,039,194.00\n",
      "México                 $26,806,554,520.00\n",
      "Nayarit                 $5,424,668,792.00\n",
      "Nuevo León             $24,993,705,470.00\n",
      "Oaxaca                  $7,308,265,247.00\n",
      "Puebla                 $13,963,853,298.00\n",
      "Querétaro               $4,570,837,270.00\n",
      "Quintana Roo            $8,244,767,894.00\n",
      "San Luis Potosí         $5,802,523,745.00\n",
      "Sinaloa                $12,921,917,374.00\n",
      "Sonora                  $9,287,051,294.00\n",
      "Tabasco                 $7,026,824,800.00\n",
      "Tamaulipas             $14,352,991,111.00\n",
      "Tlaxcala                $3,437,948,997.00\n",
      "Veracruz               $18,311,994,688.00\n",
      "Yucatán                 $9,599,388,566.00\n",
      "Zacatecas               $3,814,796,752.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\AppData\\Local\\Temp\\ipykernel_12592\\538922952.py:100: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  masa_salarial_estado = df_ocupada.groupby('ent_nombre').apply(lambda x: (x['ingocup'] * x['fac_tri']).sum())\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def calcular_indicadores_enoe(df):\n",
    "    \"\"\"\n",
    "    Calcula y muestra una serie de indicadores demográficos y económicos \n",
    "    a partir de un DataFrame de la ENOE.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): El DataFrame ya cargado.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Iniciando Cálculos de Indicadores ---\")\n",
    "    \n",
    "    # --- 1. Limpieza y Preparación de Datos ---\n",
    "    # Asegurar que las columnas clave para el filtrado y cálculo sean del tipo correcto.\n",
    "    df['r_def'] = df['r_def'].astype(str).str.strip()\n",
    "    df['c_res'] = pd.to_numeric(df['c_res'], errors='coerce')\n",
    "    columnas_numericas = [\n",
    "        'fac_tri', 'sex', 'eda', 'clase1', 'clase2', \n",
    "        'ingocup', 'ing_x_hrs', 'ent'\n",
    "    ]\n",
    "    for col in columnas_numericas:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # --- 2. Aplicación de Filtros Base ---\n",
    "    # El universo para la mayoría de los cálculos son los residentes con entrevista completa.\n",
    "    df_base = df[(df['r_def'] == '0.0') & (df['c_res'].isin([1, 3]))].copy()\n",
    "    \n",
    "    if df_base.empty:\n",
    "        print(\"❌ Error Crítico: No se encontraron registros válidos (r_def='0.0' y c_res=1 o 3). No se pueden continuar los cálculos.\")\n",
    "        return\n",
    "\n",
    "    # --- 3. Cálculos Principales y Presentación ---\n",
    "    print(\"\\n--- Resultados: Población General ---\")\n",
    "    \n",
    "    # Población Total\n",
    "    poblacion_total = df_base['fac_tri'].sum()\n",
    "    print(f\"1. Población Total Estimada: {poblacion_total:,.0f}\")\n",
    "    \n",
    "    # Población por Género\n",
    "    poblacion_hombres = df_base[df_base['sex'] == 1]['fac_tri'].sum()\n",
    "    poblacion_mujeres = df_base[df_base['sex'] == 2]['fac_tri'].sum()\n",
    "    print(f\"2. Total de Hombres: {poblacion_hombres:,.0f}\")\n",
    "    print(f\"3. Total de Mujeres: {poblacion_mujeres:,.0f}\")\n",
    "\n",
    "    # --- Cálculos Adicionales ---\n",
    "    # Filtro para población de 15 años y más\n",
    "    df_15_y_mas = df_base[df_base['eda'].between(15, 98)].copy()\n",
    "    \n",
    "    # PEA por Género\n",
    "    df_pea = df_15_y_mas[df_15_y_mas['clase1'] == 1]\n",
    "    pea_hombres = df_pea[df_pea['sex'] == 1]['fac_tri'].sum()\n",
    "    pea_mujeres = df_pea[df_pea['sex'] == 2]['fac_tri'].sum()\n",
    "    print(f\"4. PEA Hombres: {pea_hombres:,.0f}\")\n",
    "    print(f\"5. PEA Mujeres: {pea_mujeres:,.0f}\")\n",
    "\n",
    "    # --- Cálculos de Ingreso (sobre la población ocupada) ---\n",
    "    df_ocupada = df_15_y_mas[df_15_y_mas['clase2'] == 1].copy()\n",
    "    \n",
    "    def weighted_average(df, value_col, weight_col):\n",
    "        df_filtered = df.dropna(subset=[value_col, weight_col])\n",
    "        if df_filtered.empty or df_filtered[weight_col].sum() == 0:\n",
    "            return 0\n",
    "        return np.average(df_filtered[value_col], weights=df_filtered[weight_col])\n",
    "\n",
    "    # Ingreso Promedio Mensual por Género\n",
    "    ing_prom_mujer = weighted_average(df_ocupada[df_ocupada['sex'] == 2], 'ingocup', 'fac_tri')\n",
    "    ing_prom_hombre = weighted_average(df_ocupada[df_ocupada['sex'] == 1], 'ingocup', 'fac_tri')\n",
    "    print(f\"6. Ingreso Promedio Mensual (Mujer): ${ing_prom_mujer:,.2f}\")\n",
    "    print(f\"7. Ingreso Promedio Mensual (Hombre): ${ing_prom_hombre:,.2f}\")\n",
    "\n",
    "    # Diccionario de Entidades\n",
    "    entidades = {\n",
    "        1: 'Aguascalientes', 2: 'Baja California', 3: 'Baja California Sur', 4: 'Campeche',\n",
    "        5: 'Coahuila', 6: 'Colima', 7: 'Chiapas', 8: 'Chihuahua', 9: 'Ciudad de México',\n",
    "        10: 'Durango', 11: 'Guanajuato', 12: 'Guerrero', 13: 'Hidalgo', 14: 'Jalisco',\n",
    "        15: 'México', 16: 'Michoacán', 17: 'Morelos', 18: 'Nayarit', 19: 'Nuevo León',\n",
    "        20: 'Oaxaca', 21: 'Puebla', 22: 'Querétaro', 23: 'Quintana Roo', 24: 'San Luis Potosí',\n",
    "        25: 'Sinaloa', 26: 'Sonora', 27: 'Tabasco', 28: 'Tamaulipas', 29: 'Tlaxcala',\n",
    "        30: 'Veracruz', 31: 'Yucatán', 32: 'Zacatecas'\n",
    "    }\n",
    "    df_ocupada['ent_nombre'] = df_ocupada['ent'].map(entidades)\n",
    "\n",
    "    # Ingreso Promedio Mensual por Estado\n",
    "    ing_prom_estado = df_ocupada.groupby('ent_nombre').apply(lambda x: weighted_average(x, 'ingocup', 'fac_tri'))\n",
    "    print(\"\\n8. Ingreso Promedio Mensual por Estado:\")\n",
    "    print(ing_prom_estado.map('${:,.2f}'.format).to_string())\n",
    "\n",
    "    # Ingreso Promedio por Hora\n",
    "    ing_hora_total = weighted_average(df_ocupada, 'ing_x_hrs', 'fac_tri')\n",
    "    ing_hora_mujer = weighted_average(df_ocupada[df_ocupada['sex'] == 2], 'ing_x_hrs', 'fac_tri')\n",
    "    ing_hora_hombre = weighted_average(df_ocupada[df_ocupada['sex'] == 1], 'ing_x_hrs', 'fac_tri')\n",
    "    print(f\"\\n9. Ingreso Promedio por Hora (Total): ${ing_hora_total:,.2f}\")\n",
    "    print(f\"10. Ingreso Promedio por Hora (Mujer): ${ing_hora_mujer:,.2f}\")\n",
    "    print(f\"    Ingreso Promedio por Hora (Hombre): ${ing_hora_hombre:,.2f}\")\n",
    "\n",
    "    # Masa Salarial\n",
    "    masa_salarial_total = (df_ocupada['ingocup'] * df_ocupada['fac_tri']).sum()\n",
    "    masa_salarial_estado = df_ocupada.groupby('ent_nombre').apply(lambda x: (x['ingocup'] * x['fac_tri']).sum())\n",
    "    print(f\"\\n11. Masa Salarial Total Mensual: ${masa_salarial_total:,.2f}\")\n",
    "    print(\"\\n12. Masa Salarial Mensual por Estado:\")\n",
    "    print(masa_salarial_estado.map('${:,.2f}'.format).to_string())\n",
    "\n",
    "\n",
    "# --- Ejecución del Script ---\n",
    "if __name__ == \"__main__\":\n",
    "    YEAR_A_ANALIZAR = 2025\n",
    "    QUARTER_A_ANALIZAR = 2\n",
    "    \n",
    "    print(f\"--- Iniciando análisis para {YEAR_A_ANALIZAR} T{QUARTER_A_ANALIZAR} ---\")\n",
    "    \n",
    "    # --- 1. Carga de datos ---\n",
    "    file_format = 'dta'\n",
    "    year_short = str(YEAR_A_ANALIZAR)[-2:]\n",
    "    dir_name = f\"ENOE_{YEAR_A_ANALIZAR}_{QUARTER_A_ANALIZAR}\"\n",
    "    file_name = f\"ENOE_SDEMT{QUARTER_A_ANALIZAR}{year_short}.dta\"\n",
    "    file_path = os.path.join(\"data\", f\"ENOE_{file_format}\", dir_name, file_name)\n",
    "    \n",
    "    print(f\"Buscando archivo en: {file_path}\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ Error: No se encontró el archivo. Ejecuta el script de descarga primero.\")\n",
    "    else:\n",
    "        try:\n",
    "            df_enoe = pd.read_stata(file_path, convert_categoricals=False)\n",
    "            print(f\"✅ Archivo cargado exitosamente. {len(df_enoe)} registros leídos.\")\n",
    "            \n",
    "            # --- 2. Ejecutar análisis completo ---\n",
    "            calcular_indicadores_enoe(df_enoe)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Ocurrió un error durante el análisis: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddfa419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r_def</th>\n",
       "      <th>loc</th>\n",
       "      <th>mun</th>\n",
       "      <th>est</th>\n",
       "      <th>est_d_tri</th>\n",
       "      <th>est_d_men</th>\n",
       "      <th>ageb</th>\n",
       "      <th>t_loc_tri</th>\n",
       "      <th>t_loc_men</th>\n",
       "      <th>cd_a</th>\n",
       "      <th>...</th>\n",
       "      <th>scian</th>\n",
       "      <th>t_tra</th>\n",
       "      <th>emp_ppal</th>\n",
       "      <th>tue_ppal</th>\n",
       "      <th>trans_ppal</th>\n",
       "      <th>mh_fil2</th>\n",
       "      <th>mh_col</th>\n",
       "      <th>sec_ins</th>\n",
       "      <th>tipo</th>\n",
       "      <th>mes_cal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>681.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>782.0</td>\n",
       "      <td>782.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423739</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423740</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423741</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>754.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423742</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423743</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>422854 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       r_def  loc   mun   est  est_d_tri  est_d_men  ageb  t_loc_tri  \\\n",
       "0        0.0  NaN  15.0  30.0      681.0      681.0   0.0        1.0   \n",
       "1        0.0  NaN  12.0  30.0      681.0      681.0   0.0        1.0   \n",
       "2        0.0  NaN  97.0  30.0      783.0      783.0   0.0        1.0   \n",
       "3        0.0  NaN  98.0  20.0      782.0      782.0   0.0        1.0   \n",
       "4        0.0  NaN  20.0  20.0      713.0      713.0   0.0        1.0   \n",
       "...      ...  ...   ...   ...        ...        ...   ...        ...   \n",
       "423739   0.0  NaN  48.0  20.0      996.0      996.0   0.0        3.0   \n",
       "423740   0.0  NaN   1.0  20.0      517.0      517.0   0.0        4.0   \n",
       "423741   0.0  NaN  21.0  10.0      754.0      754.0   0.0        4.0   \n",
       "423742   0.0  NaN  32.0  20.0      845.0      845.0   0.0        4.0   \n",
       "423743   0.0  NaN  40.0  10.0     1205.0     1205.0   0.0        4.0   \n",
       "\n",
       "        t_loc_men  cd_a  ...  scian  t_tra  emp_ppal  tue_ppal  trans_ppal  \\\n",
       "0             1.0   1.0  ...    7.0    1.0       2.0       2.0         0.0   \n",
       "1             1.0   1.0  ...    0.0    0.0       0.0       0.0         0.0   \n",
       "2             1.0   2.0  ...    8.0    1.0       2.0       2.0         0.0   \n",
       "3             1.0   2.0  ...   21.0    1.0       1.0       2.0         0.0   \n",
       "4             1.0   5.0  ...    0.0    0.0       0.0       0.0         0.0   \n",
       "...           ...   ...  ...    ...    ...       ...       ...         ...   \n",
       "423739        3.0  85.0  ...    0.0    0.0       0.0       0.0         0.0   \n",
       "423740        4.0  86.0  ...    8.0    1.0       2.0       2.0         0.0   \n",
       "423741        4.0  86.0  ...    7.0    2.0       2.0       2.0         0.0   \n",
       "423742        4.0  86.0  ...    0.0    0.0       0.0       0.0         0.0   \n",
       "423743        4.0  86.0  ...    0.0    0.0       0.0       0.0         0.0   \n",
       "\n",
       "        mh_fil2  mh_col  sec_ins  tipo  mes_cal  \n",
       "0           3.0     2.0      2.0   1.0      4.0  \n",
       "1           0.0     0.0      0.0   1.0      4.0  \n",
       "2           3.0     2.0      2.0   1.0      5.0  \n",
       "3           3.0     1.0     11.0   1.0      4.0  \n",
       "4           0.0     0.0      0.0   1.0      5.0  \n",
       "...         ...     ...      ...   ...      ...  \n",
       "423739      0.0     0.0      0.0   1.0      4.0  \n",
       "423740      3.0     2.0      2.0   1.0      4.0  \n",
       "423741      3.0     8.0      4.0   1.0      4.0  \n",
       "423742      0.0     0.0      0.0   1.0      5.0  \n",
       "423743      0.0     0.0      0.0   1.0      5.0  \n",
       "\n",
       "[422854 rows x 114 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tablas a través del tiempo y por estados\n",
    "# Datos ya trabajados\n",
    "#\n",
    "\n",
    "# 1. Porcentajes de ocupación por rango de edad\n",
    "# 2. Ingresos por percentil \n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e31239c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r_def\n",
       "0.0     422854\n",
       "15.0       890\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_enoe[\"r_def\"].describe()\n",
    "df_enoe[\"r_def\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfcc2b68",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b162b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Definición del Rango de la Serie de Tiempo ---\n",
      "--- ⚠️ Saltando periodo 2020 T2 (No disponible o no oficial). ---\n",
      "--- ⚠️ Saltando periodo 2020 T3 (No disponible o no oficial). ---\n",
      "\n",
      "===========================================================\n",
      "  INICIANDO PROCESAMIENTO DE 80 TRIMESTRES\n",
      "===========================================================\n",
      "\n",
      "--- ⏳ Procesando: 2005 T1 ---\n",
      "✅ Archivo cargado exitosamente. 424,007 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2005 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2005 T2 ---\n",
      "✅ Archivo cargado exitosamente. 428,727 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2005 T2 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2005 T3 ---\n",
      "✅ Archivo cargado exitosamente. 421,751 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2005 T3 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2005 T4 ---\n",
      "✅ Archivo cargado exitosamente. 423,757 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2005 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2006 T1 ---\n",
      "✅ Archivo cargado exitosamente. 426,160 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2006 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2006 T2 ---\n",
      "✅ Archivo cargado exitosamente. 424,579 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2006 T2 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2006 T3 ---\n",
      "✅ Archivo cargado exitosamente. 423,305 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2006 T3 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2006 T4 ---\n",
      "✅ Archivo cargado exitosamente. 421,581 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2006 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2007 T1 ---\n",
      "✅ Archivo cargado exitosamente. 423,910 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2007 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2007 T2 ---\n",
      "✅ Archivo cargado exitosamente. 422,591 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2007 T2 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2007 T3 ---\n",
      "✅ Archivo cargado exitosamente. 418,327 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2007 T3 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2007 T4 ---\n",
      "✅ Archivo cargado exitosamente. 409,422 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2007 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2008 T1 ---\n",
      "✅ Archivo cargado exitosamente. 416,538 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2008 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2008 T2 ---\n",
      "✅ Archivo cargado exitosamente. 415,610 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2008 T2 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2008 T3 ---\n",
      "✅ Archivo cargado exitosamente. 410,219 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2008 T3 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2008 T4 ---\n",
      "✅ Archivo cargado exitosamente. 407,232 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2008 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2009 T1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\AppData\\Local\\Temp\\ipykernel_12592\\720325823.py:142: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  df = pd.read_stata(file_path, convert_categoricals=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo cargado exitosamente. 407,725 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2009 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2009 T2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\AppData\\Local\\Temp\\ipykernel_12592\\720325823.py:142: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  df = pd.read_stata(file_path, convert_categoricals=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo cargado exitosamente. 405,529 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2009 T2 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2009 T3 ---\n",
      "✅ Archivo cargado exitosamente. 402,919 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2009 T3 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2009 T4 ---\n",
      "✅ Archivo cargado exitosamente. 403,862 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2009 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2010 T1 ---\n",
      "✅ Archivo cargado exitosamente. 406,797 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2010 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2010 T2 ---\n",
      "✅ Archivo cargado exitosamente. 408,164 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2010 T2 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2010 T3 ---\n",
      "✅ Archivo cargado exitosamente. 405,533 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2010 T3 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2010 T4 ---\n",
      "✅ Archivo cargado exitosamente. 401,524 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2010 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2011 T1 ---\n",
      "✅ Archivo cargado exitosamente. 402,117 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2011 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2011 T2 ---\n",
      "✅ Archivo cargado exitosamente. 400,977 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2011 T2 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2011 T3 ---\n",
      "✅ Archivo cargado exitosamente. 399,716 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2011 T3 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2011 T4 ---\n",
      "✅ Archivo cargado exitosamente. 399,467 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2011 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2012 T1 ---\n",
      "✅ Archivo cargado exitosamente. 401,880 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2012 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2012 T2 ---\n",
      "✅ Archivo cargado exitosamente. 400,544 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2012 T2 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2012 T3 ---\n",
      "✅ Archivo cargado exitosamente. 397,893 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2012 T3 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2012 T4 ---\n",
      "✅ Archivo cargado exitosamente. 392,632 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2012 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2013 T1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\AppData\\Local\\Temp\\ipykernel_12592\\720325823.py:142: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  df = pd.read_stata(file_path, convert_categoricals=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo cargado exitosamente. 392,937 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2013 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2013 T2 ---\n",
      "✅ Archivo cargado exitosamente. 393,107 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2013 T2 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2013 T3 ---\n",
      "✅ Archivo cargado exitosamente. 394,472 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2013 T3 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2013 T4 ---\n",
      "✅ Archivo cargado exitosamente. 400,354 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2013 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2014 T1 ---\n",
      "✅ Archivo cargado exitosamente. 404,014 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2014 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2014 T2 ---\n",
      "✅ Archivo cargado exitosamente. 406,088 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2014 T2 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2014 T3 ---\n",
      "✅ Archivo cargado exitosamente. 405,803 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2014 T3 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2014 T4 ---\n",
      "✅ Archivo cargado exitosamente. 404,640 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2014 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2015 T1 ---\n",
      "✅ Archivo cargado exitosamente. 404,432 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2015 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2015 T2 ---\n",
      "✅ Archivo cargado exitosamente. 403,865 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2015 T2 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2015 T3 ---\n",
      "✅ Archivo cargado exitosamente. 401,825 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2015 T3 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2015 T4 ---\n",
      "✅ Archivo cargado exitosamente. 398,943 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2015 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2016 T1 ---\n",
      "✅ Archivo cargado exitosamente. 397,458 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2016 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2016 T2 ---\n",
      "✅ Archivo cargado exitosamente. 397,156 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2016 T2 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2016 T3 ---\n",
      "✅ Archivo cargado exitosamente. 391,934 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2016 T3 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2016 T4 ---\n",
      "✅ Archivo cargado exitosamente. 391,418 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2016 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2017 T1 ---\n",
      "✅ Archivo cargado exitosamente. 392,047 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2017 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2017 T2 ---\n",
      "✅ Archivo cargado exitosamente. 398,017 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2017 T2 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2017 T3 ---\n",
      "✅ Archivo cargado exitosamente. 392,178 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2017 T3 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2017 T4 ---\n",
      "✅ Archivo cargado exitosamente. 391,620 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2017 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2018 T1 ---\n",
      "✅ Archivo cargado exitosamente. 390,712 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2018 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2018 T2 ---\n",
      "✅ Archivo cargado exitosamente. 392,257 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2018 T2 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2018 T3 ---\n",
      "✅ Archivo cargado exitosamente. 390,837 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2018 T3 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2018 T4 ---\n",
      "✅ Archivo cargado exitosamente. 390,612 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2018 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2019 T1 ---\n",
      "✅ Archivo cargado exitosamente. 406,036 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2019 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2019 T2 ---\n",
      "✅ Archivo cargado exitosamente. 407,431 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2019 T2 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2019 T3 ---\n",
      "✅ Archivo cargado exitosamente. 405,449 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2019 T3 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2019 T4 ---\n",
      "✅ Archivo cargado exitosamente. 402,536 registros. Ponderador: FAC\n",
      "❌ Error Crítico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2019 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2020 T1 ---\n",
      "❌ Error Crítico: Archivo no encontrado en: Data/ENOE_dta\\ENOE_2020_1\\ENOEN_SDEMT120.dta\n",
      "--- 🚫 Se agregó NA/NaN para 2020 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2020 T4 ---\n",
      "✅ Archivo cargado exitosamente. 356,790 registros. Ponderador: FAC_TRI\n",
      "❌ Error Crítico: Columna de ponderador 'FAC_TRI' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2020 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2021 T1 ---\n",
      "✅ Archivo cargado exitosamente. 350,728 registros. Ponderador: FAC_TRI\n",
      "❌ Error Crítico: Columna de ponderador 'FAC_TRI' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2021 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2021 T2 ---\n",
      "✅ Archivo cargado exitosamente. 381,319 registros. Ponderador: FAC_TRI\n",
      "❌ Error Crítico: Columna de ponderador 'FAC_TRI' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2021 T2 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2021 T3 ---\n",
      "✅ Archivo cargado exitosamente. 428,160 registros. Ponderador: FAC_TRI\n",
      "❌ Error Crítico: Columna de ponderador 'FAC_TRI' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2021 T3 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2021 T4 ---\n",
      "✅ Archivo cargado exitosamente. 434,826 registros. Ponderador: FAC_TRI\n",
      "❌ Error Crítico: Columna de ponderador 'FAC_TRI' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2021 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2022 T1 ---\n",
      "✅ Archivo cargado exitosamente. 403,652 registros. Ponderador: FAC_TRI\n",
      "❌ Error Crítico: Columna de ponderador 'FAC_TRI' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2022 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2022 T2 ---\n",
      "✅ Archivo cargado exitosamente. 405,959 registros. Ponderador: FAC_TRI\n",
      "❌ Error Crítico: Columna de ponderador 'FAC_TRI' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2022 T2 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2022 T3 ---\n",
      "✅ Archivo cargado exitosamente. 398,591 registros. Ponderador: FAC_TRI\n",
      "❌ Error Crítico: Columna de ponderador 'FAC_TRI' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2022 T3 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2022 T4 ---\n",
      "✅ Archivo cargado exitosamente. 396,629 registros. Ponderador: FAC_TRI\n",
      "❌ Error Crítico: Columna de ponderador 'FAC_TRI' no encontrada.\n",
      "--- 🚫 Se agregó NA/NaN para 2022 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2023 T1 ---\n",
      "❌ Error Crítico: Archivo no encontrado en: Data/ENOE_dta\\ENOE_2023_1\\SDEMT123.dta\n",
      "--- 🚫 Se agregó NA/NaN para 2023 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2023 T2 ---\n",
      "❌ Error Crítico: Archivo no encontrado en: Data/ENOE_dta\\ENOE_2023_2\\SDEMT223.dta\n",
      "--- 🚫 Se agregó NA/NaN para 2023 T2 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2023 T3 ---\n",
      "❌ Error Crítico: Archivo no encontrado en: Data/ENOE_dta\\ENOE_2023_3\\SDEMT323.dta\n",
      "--- 🚫 Se agregó NA/NaN para 2023 T3 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2023 T4 ---\n",
      "❌ Error Crítico: Archivo no encontrado en: Data/ENOE_dta\\ENOE_2023_4\\SDEMT423.dta\n",
      "--- 🚫 Se agregó NA/NaN para 2023 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2024 T1 ---\n",
      "❌ Error Crítico: Archivo no encontrado en: Data/ENOE_dta\\ENOE_2024_1\\SDEMT124.dta\n",
      "--- 🚫 Se agregó NA/NaN para 2024 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2024 T2 ---\n",
      "❌ Error Crítico: Archivo no encontrado en: Data/ENOE_dta\\ENOE_2024_2\\SDEMT224.dta\n",
      "--- 🚫 Se agregó NA/NaN para 2024 T2 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2024 T3 ---\n",
      "❌ Error Crítico: Archivo no encontrado en: Data/ENOE_dta\\ENOE_2024_3\\SDEMT324.dta\n",
      "--- 🚫 Se agregó NA/NaN para 2024 T3 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2024 T4 ---\n",
      "❌ Error Crítico: Archivo no encontrado en: Data/ENOE_dta\\ENOE_2024_4\\SDEMT424.dta\n",
      "--- 🚫 Se agregó NA/NaN para 2024 T4 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2025 T1 ---\n",
      "❌ Error Crítico: Archivo no encontrado en: Data/ENOE_dta\\ENOE_2025_1\\SDEMT125.dta\n",
      "--- 🚫 Se agregó NA/NaN para 2025 T1 y se prosigue. ---\n",
      "\n",
      "--- ⏳ Procesando: 2025 T2 ---\n",
      "❌ Error Crítico: Archivo no encontrado en: Data/ENOE_dta\\ENOE_2025_2\\SDEMT225.dta\n",
      "--- 🚫 Se agregó NA/NaN para 2025 T2 y se prosigue. ---\n",
      "\n",
      "===========================================================\n",
      "      ✅ BASE DE SERIE DE TIEMPO NACIONAL CREADA\n",
      "      (Incluye nuevos indicadores estratégicos)\n",
      "===========================================================\n",
      "         year  quarter\n",
      "periodo               \n",
      "2005-T1  2005        1\n",
      "2005-T2  2005        2\n",
      "2005-T3  2005        3\n",
      "2005-T4  2005        4\n",
      "2006-T1  2006        1\n",
      "\n",
      "===========================================================\n",
      "      ✅ BASE DE SERIE DE TIEMPO ESTATAL CREADA\n",
      "      (Incluye nuevos indicadores estratégicos)\n",
      "===========================================================\n",
      "   year  quarter  ent_code           ent_nombre  periodo\n",
      "0  2005        1         1       Aguascalientes  2005-T1\n",
      "1  2005        1         2      Baja California  2005-T1\n",
      "2  2005        1         3  Baja California Sur  2005-T1\n",
      "3  2005        1         4             Campeche  2005-T1\n",
      "4  2005        1         5             Coahuila  2005-T1\n"
     ]
    }
   ],
   "source": [
    "# versión con cambio en los nombres de las bases de datos \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# FUNCIONES DE UTILIDAD\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def weighted_average(df, value_col, weight_col):\n",
    "    \"\"\"Calcula el promedio ponderado de una columna usando pesos (factores de expansión).\"\"\"\n",
    "    df_filtered = df.dropna(subset=[value_col, weight_col])\n",
    "    \n",
    "    # Excluir valores de ingreso no válidos (generalmente negativos o no especificados, si se aplica)\n",
    "    if value_col in ['ingocup', 'ing_x_hrs']:\n",
    "        df_filtered = df_filtered[df_filtered[value_col] > 0].copy()\n",
    "    \n",
    "    if df_filtered.empty or df_filtered[weight_col].sum() == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    return np.average(df_filtered[value_col], weights=df_filtered[weight_col])\n",
    "\n",
    "# Diccionario de Entidades para mapear códigos a nombres\n",
    "ENTIDADES = {\n",
    "    1: 'Aguascalientes', 2: 'Baja California', 3: 'Baja California Sur', 4: 'Campeche',\n",
    "    5: 'Coahuila', 6: 'Colima', 7: 'Chiapas', 8: 'Chihuahua', 9: 'Ciudad de México',\n",
    "    10: 'Durango', 11: 'Guanajuato', 12: 'Guerrero', 13: 'Hidalgo', 14: 'Jalisco',\n",
    "    15: 'México', 16: 'Michoacán', 17: 'Morelos', 18: 'Nayarit', 19: 'Nuevo León',\n",
    "    20: 'Oaxaca', 21: 'Puebla', 22: 'Querétaro', 23: 'Quintana Roo', 24: 'San Luis Potosí',\n",
    "    25: 'Sinaloa', 26: 'Sonora', 27: 'Tabasco', 28: 'Tamaulipas', 29: 'Tlaxcala',\n",
    "    30: 'Veracruz', 31: 'Yucatán', 32: 'Zacatecas'\n",
    "}\n",
    "\n",
    "def obtener_nombre_archivo(year, quarter, file_format='dta'):\n",
    "    \"\"\"Determina el nombre del archivo SDEMT según el periodo.\"\"\"\n",
    "    year_short = str(year)[-2:]\n",
    "    \n",
    "    # Periodo 1: 2005 T1 a 2018 T4 (Mayúsculas)\n",
    "    if year <= 2018:\n",
    "        base_name = f\"SDEMT{quarter}{year_short}\".upper()\n",
    "    \n",
    "    # Periodo 2: 2019 T1 a 2019 T4 (Minúsculas)\n",
    "    elif year == 2019:\n",
    "        base_name = f\"sdemt{quarter}{year_short}\".lower()\n",
    "    \n",
    "    # Periodo 3: 2020 T3 a 2022 T4 (Prefijo ENOEN_)\n",
    "    elif 2020 <= year <= 2022:\n",
    "        # 2020 T1 y T2 no tienen datos o son no oficiales (se manejan como \"saltados\" en el script principal)\n",
    "        base_name = f\"ENOEN_SDEMT{quarter}{year_short}\".upper()\n",
    "    \n",
    "    # Periodo 4: 2023 T1 en adelante (Vuelve a Mayúsculas/Patrón consistente con el documento)\n",
    "    else: # year >= 2023\n",
    "        base_name = f\"SDEMT{quarter}{year_short}\".upper()\n",
    "        \n",
    "    dir_name = f\"ENOE_{year}_{quarter}\"\n",
    "    file_name = f\"{base_name}.{file_format}\"\n",
    "    # Asume que los archivos están en data/dta/ENOE_YYYY_Q/SDEMT...\n",
    "    file_path = os.path.join(\"Data/ENOE_dta\", dir_name, file_name) \n",
    "    \n",
    "    return file_path\n",
    "\n",
    "def pedir_rango_trimestral():\n",
    "    \"\"\"Pide al usuario el rango de años y trimestres para generar la serie de tiempo.\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            print(\"\\n--- Definición del Rango de la Serie de Tiempo ---\")\n",
    "            start_year = int(input(\"Ingrese el AÑO de inicio (e.g., 2018): \"))\n",
    "            start_quarter = int(input(\"Ingrese el TRIMESTRE de inicio (1 a 4): \"))\n",
    "            end_year = int(input(\"Ingrese el AÑO final (e.g., 2024): \"))\n",
    "            end_quarter = int(input(\"Ingrese el TRIMESTRE final (1 a 4): \"))\n",
    "            \n",
    "            if not (1 <= start_quarter <= 4 and 1 <= end_quarter <= 4):\n",
    "                raise ValueError(\"El trimestre debe ser un número entre 1 y 4.\")\n",
    "            \n",
    "            start_date = datetime(start_year, start_quarter * 3 - 2, 1)\n",
    "            end_date = datetime(end_year, end_quarter * 3 - 2, 1)\n",
    "\n",
    "            if start_date > end_date:\n",
    "                raise ValueError(\"El periodo de inicio debe ser anterior o igual al periodo final.\")\n",
    "                \n",
    "            break\n",
    "        except ValueError as e:\n",
    "            print(f\"Entrada inválida: {e}. Por favor, intente de nuevo.\")\n",
    "            \n",
    "    # Generar la secuencia de trimestres\n",
    "    periodos = []\n",
    "    current_year = start_year\n",
    "    current_quarter = start_quarter\n",
    "    \n",
    "    while current_year < end_year or (current_year == end_year and current_quarter <= end_quarter):\n",
    "        \n",
    "        # Manejo de trimestres faltantes (2020 T2 y T3 no oficiales/disponibles)\n",
    "        if current_year == 2020 and current_quarter in [2, 3]:\n",
    "            print(f\"--- ⚠️ Saltando periodo {current_year} T{current_quarter} (No disponible o no oficial). ---\")\n",
    "            pass # No se añade el periodo a la lista para no intentar cargarlo.\n",
    "            \n",
    "        else:\n",
    "            periodos.append((current_year, current_quarter))\n",
    "            \n",
    "        # Pasar al siguiente trimestre\n",
    "        if current_quarter == 4:\n",
    "            current_quarter = 1\n",
    "            current_year += 1\n",
    "        else:\n",
    "            current_quarter += 1\n",
    "            \n",
    "    return periodos\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# FUNCIÓN PRINCIPAL DE PROCESAMIENTO TRIMESTRAL\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def procesar_trimestre_enoe(year, quarter, file_format='dta'):\n",
    "    \"\"\"\n",
    "    Carga, limpia y calcula indicadores clave a nivel nacional y estatal \n",
    "    para un trimestre específico.\n",
    "    \"\"\"\n",
    "    periodo_str = f\"{year} T{quarter}\"\n",
    "    print(f\"\\n--- ⏳ Procesando: {periodo_str} ---\")\n",
    "\n",
    "    # --- 1. Obtener Ruta y Ponderador ---\n",
    "    file_path = obtener_nombre_archivo(year, quarter, file_format)\n",
    "    \n",
    "    # Determinar el campo ponderador correcto según el periodo \n",
    "    if year < 2020 or (year == 2020 and quarter < 3):\n",
    "        PONDERATOR = 'FAC'\n",
    "    else:\n",
    "        PONDERATOR = 'FAC_TRI'\n",
    "    \n",
    "    # --- 2. Carga de Datos y Manejo de Errores (Debugging) ---\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ Error Crítico: Archivo no encontrado en: {file_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        if file_format == 'dta':\n",
    "            # Se usa `encoding='latin-1'` si se encuentran problemas con codificación de texto\n",
    "            df = pd.read_stata(file_path, convert_categoricals=False) \n",
    "        elif file_format == 'csv':\n",
    "            df = pd.read_csv(file_path)\n",
    "        else:\n",
    "            raise ValueError(\"Formato de archivo no soportado.\")\n",
    "        \n",
    "        if df.empty:\n",
    "            print(f\"❌ Error de Carga: Archivo encontrado, pero vacío: {file_path}\")\n",
    "            return None, None\n",
    "            \n",
    "        print(f\"✅ Archivo cargado exitosamente. {len(df):,} registros. Ponderador: {PONDERATOR}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ocurrió un error de lectura de datos en {file_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # --- 3. Limpieza y Preparación de Datos ---\n",
    "    \n",
    "    # Conversión de tipos de datos esenciales y estandarización de nombres\n",
    "    columnas_requeridas = [\n",
    "        PONDERATOR, 'sex', 'eda', 'clase1', 'clase2', 'c_res', 'r_def', 'ent',\n",
    "        'ingocup', 'ing_x_hrs', 'pos_ocu', 'emp_ppal', 'sub_o' # Indicadores estratégicos\n",
    "    ]\n",
    "    \n",
    "    for col in columnas_requeridas:\n",
    "        if col not in df.columns:\n",
    "            # Añadir columna con NaN/0 si falta, para evitar errores en cálculos posteriores (excepto ponderador)\n",
    "            if col == PONDERATOR:\n",
    "                 print(f\"❌ Error Crítico: Columna de ponderador '{PONDERATOR}' no encontrada.\")\n",
    "                 return None, None\n",
    "            df[col] = np.nan if col not in ['r_def', 'c_res'] else 0\n",
    "            print(f\"⚠️ Columna '{col}' no encontrada. Se añadió con NaN/0 para proseguir.\")\n",
    "\n",
    "    # Conversión de tipos\n",
    "    df['r_def'] = df['r_def'].astype(str).str.strip()\n",
    "    for col in ['sex', 'eda', 'clase1', 'clase2', 'c_res', 'ent', 'pos_ocu', 'emp_ppal', 'sub_o']:\n",
    "         # Convertir a numérico, forzando errores a NaN, luego a entero (si es posible)\n",
    "         df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "    for col in ['ingocup', 'ing_x_hrs', PONDERATOR]:\n",
    "         df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "\n",
    "    # CRITERIO GENERAL DE FILTRADO (POBLACIÓN DE 15 AÑOS Y MÁS)\n",
    "    # R_DEF='00' y (C_RES=1 o 3) y (EDA>=15 y EDA<=98) [cite: 148]\n",
    "    \n",
    "    # 1. Población total residente\n",
    "    df_base = df[(df['r_def'] == '00') & (df['c_res'].isin([1, 3]))].copy()\n",
    "\n",
    "    # 2. Población en Edad de Trabajar (PET) 15 años y más\n",
    "    df_15_y_mas = df_base[df_base['eda'].between(15, 98)].copy()\n",
    "    \n",
    "    if df_15_y_mas.empty:\n",
    "        print(\"❌ Error de Filtro: No se encontraron registros válidos después del filtro PET.\")\n",
    "        return None, None\n",
    "    \n",
    "    # Asignación de nombres de estado\n",
    "    df_base['ent_nombre'] = df_base['ent'].map(ENTIDADES)\n",
    "    df_15_y_mas['ent_nombre'] = df_15_y_mas['ent'].map(ENTIDADES)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # --- 4. CÁLCULOS A NIVEL NACIONAL ---\n",
    "    # ------------------------------------------------------------------\n",
    "    \n",
    "    # Subconjuntos basados en campos precodificados y el criterio general [cite: 147]\n",
    "    df_pea = df_15_y_mas[df_15_y_mas['clase1'] == 1].copy()      \n",
    "    df_pnea = df_15_y_mas[df_15_y_mas['clase1'] == 2].copy()\n",
    "    df_ocupada = df_15_y_mas[df_15_y_mas['clase2'] == 1].copy() \n",
    "\n",
    "    datos_nacional = {\n",
    "        # Identificadores de Tiempo\n",
    "        'year': year,\n",
    "        'quarter': quarter,\n",
    "        \n",
    "        # 1. Población\n",
    "        'pob_total': df_base[PONDERATOR].sum(),\n",
    "        'pob_15_y_mas': df_15_y_mas[PONDERATOR].sum(), # [cite: 162]\n",
    "        'pob_hombres_total': df_base[df_base['sex'] == 1][PONDERATOR].sum(),\n",
    "        'pob_mujeres_total': df_base[df_base['sex'] == 2][PONDERATOR].sum(),\n",
    "        \n",
    "        # 2. PEA y PNEA\n",
    "        'pea_total': df_pea[PONDERATOR].sum(),\n",
    "        'pea_hombres': df_pea[df_pea['sex'] == 1][PONDERATOR].sum(),\n",
    "        'pea_mujeres': df_pea[df_pea['sex'] == 2][PONDERATOR].sum(),\n",
    "        'pnea_total': df_pnea[PONDERATOR].sum(), # [cite: 163]\n",
    "        \n",
    "        # Indicadores Estratégicos (CLASE2 y CLASE1) [cite: 162, 163]\n",
    "        'ocupada_total': df_ocupada[PONDERATOR].sum(),\n",
    "        'desocupada_total': df_15_y_mas[df_15_y_mas['clase2'] == 2][PONDERATOR].sum(),\n",
    "        'pnea_disponible': df_15_y_mas[df_15_y_mas['clase2'] == 3][PONDERATOR].sum(),\n",
    "        'pnea_no_disponible': df_15_y_mas[df_15_y_mas['clase2'] == 4][PONDERATOR].sum(),\n",
    "        \n",
    "        # Indicadores Estratégicos (POSICIÓN EN LA OCUPACIÓN - Ocupados) [cite: 163]\n",
    "        'subordinados_remunerados': df_ocupada[df_ocupada['pos_ocu'] == 1][PONDERATOR].sum(),\n",
    "        'empleadores': df_ocupada[df_ocupada['pos_ocu'] == 2][PONDERATOR].sum(),\n",
    "        'cuenta_propia': df_ocupada[df_ocupada['pos_ocu'] == 3][PONDERATOR].sum(),\n",
    "        'trabajadores_no_remunerados': df_ocupada[df_ocupada['pos_ocu'] == 4][PONDERATOR].sum(),\n",
    "        \n",
    "        # Indicadores Estratégicos (CONDICIÓN DE INFORMALIDAD - Ocupados) [cite: 169]\n",
    "        'ocupacion_formal': df_ocupada[df_ocupada['emp_ppal'] == 2][PONDERATOR].sum(),\n",
    "        'ocupacion_informal': df_ocupada[df_ocupada['emp_ppal'] == 1][PONDERATOR].sum(),\n",
    "        \n",
    "        # Indicador Estratégico (SUBOCUPACIÓN - Ocupados)\n",
    "        'subocupacion': df_ocupada[df_ocupada['sub_o'] == 1][PONDERATOR].sum(),\n",
    "        \n",
    "        # 3. Ingreso Promedio\n",
    "        'ing_prom_mes_total': weighted_average(df_ocupada, 'ingocup', PONDERATOR),\n",
    "        'ing_prom_hora_total': weighted_average(df_ocupada, 'ing_x_hrs', PONDERATOR),\n",
    "    }\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # --- 5. CÁLCULOS A NIVEL ESTATAL ---\n",
    "    # ------------------------------------------------------------------\n",
    "    \n",
    "    datos_estatal = defaultdict(list)\n",
    "    \n",
    "    for ent_code, ent_name in ENTIDADES.items():\n",
    "        # Filtros base por Estado (Criterio General)\n",
    "        df_base_est = df_base[df_base['ent'] == ent_code].copy()\n",
    "        df_15_y_mas_est = df_15_y_mas[df_15_y_mas['ent'] == ent_code].copy()\n",
    "        \n",
    "        # Subconjuntos Estatales (basados en precodificados y el filtro base estatal)\n",
    "        df_pea_est = df_15_y_mas_est[df_15_y_mas_est['clase1'] == 1].copy()\n",
    "        df_pnea_est = df_15_y_mas_est[df_15_y_mas_est['clase1'] == 2].copy()\n",
    "        df_ocupada_est = df_15_y_mas_est[df_15_y_mas_est['clase2'] == 1].copy()\n",
    "        \n",
    "        # Recolección de datos\n",
    "        datos_estatal['year'].append(year)\n",
    "        datos_estatal['quarter'].append(quarter)\n",
    "        datos_estatal['ent_code'].append(ent_code)\n",
    "        datos_estatal['ent_nombre'].append(ent_name)\n",
    "        \n",
    "        # Población\n",
    "        datos_estatal['pob_total'].append(df_base_est[PONDERATOR].sum())\n",
    "        datos_estatal['pob_15_y_mas'].append(df_15_y_mas_est[PONDERATOR].sum())\n",
    "        datos_estatal['pob_hombres_total'].append(df_base_est[df_base_est['sex'] == 1][PONDERATOR].sum())\n",
    "        datos_estatal['pob_mujeres_total'].append(df_base_est[df_base_est['sex'] == 2][PONDERATOR].sum())\n",
    "        \n",
    "        # PEA y PNEA\n",
    "        datos_estatal['pea_total'].append(df_pea_est[PONDERATOR].sum())\n",
    "        datos_estatal['pnea_total'].append(df_pnea_est[PONDERATOR].sum())\n",
    "        \n",
    "        # Indicadores Estratégicos (CLASE2 y CLASE1)\n",
    "        datos_estatal['ocupada_total'].append(df_ocupada_est[PONDERATOR].sum())\n",
    "        datos_estatal['desocupada_total'].append(df_15_y_mas_est[df_15_y_mas_est['clase2'] == 2][PONDERATOR].sum())\n",
    "        datos_estatal['pnea_disponible'].append(df_15_y_mas_est[df_15_y_mas_est['clase2'] == 3][PONDERATOR].sum())\n",
    "        datos_estatal['pnea_no_disponible'].append(df_15_y_mas_est[df_15_y_mas_est['clase2'] == 4][PONDERATOR].sum())\n",
    "        \n",
    "        # Indicadores Estratégicos (POSICIÓN EN LA OCUPACIÓN - Ocupados)\n",
    "        datos_estatal['subordinados_remunerados'].append(df_ocupada_est[df_ocupada_est['pos_ocu'] == 1][PONDERATOR].sum())\n",
    "        datos_estatal['empleadores'].append(df_ocupada_est[df_ocupada_est['pos_ocu'] == 2][PONDERATOR].sum())\n",
    "        datos_estatal['cuenta_propia'].append(df_ocupada_est[df_ocupada_est['pos_ocu'] == 3][PONDERATOR].sum())\n",
    "        datos_estatal['trabajadores_no_remunerados'].append(df_ocupada_est[df_ocupada_est['pos_ocu'] == 4][PONDERATOR].sum())\n",
    "\n",
    "        # Indicadores Estratégicos (CONDICIÓN DE INFORMALIDAD - Ocupados)\n",
    "        datos_estatal['ocupacion_formal'].append(df_ocupada_est[df_ocupada_est['emp_ppal'] == 2][PONDERATOR].sum())\n",
    "        datos_estatal['ocupacion_informal'].append(df_ocupada_est[df_ocupada_est['emp_ppal'] == 1][PONDERATOR].sum())\n",
    "        \n",
    "        # Indicador Estratégico (SUBOCUPACIÓN - Ocupados)\n",
    "        datos_estatal['subocupacion'].append(df_ocupada_est[df_ocupada_est['sub_o'] == 1][PONDERATOR].sum())\n",
    "\n",
    "        # Ingreso Promedio\n",
    "        datos_estatal['ing_prom_mes_total'].append(weighted_average(df_ocupada_est, 'ingocup', PONDERATOR))\n",
    "        datos_estatal['ing_prom_hora_total'].append(weighted_average(df_ocupada_est, 'ing_x_hrs', PONDERATOR))\n",
    "\n",
    "    df_estatal_trimestre = pd.DataFrame(datos_estatal)\n",
    "    \n",
    "    return pd.Series(datos_nacional), df_estatal_trimestre\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# EJECUCIÓN DEL SCRIPT Y CONSOLIDACIÓN DE SERIES DE TIEMPO\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    periodos = pedir_rango_trimestral()\n",
    "    \n",
    "    # Inicialización para la consolidación\n",
    "    resultados_nacionales = []\n",
    "    resultados_estatales = []\n",
    "\n",
    "    print(f\"\\n===========================================================\")\n",
    "    print(f\"  INICIANDO PROCESAMIENTO DE {len(periodos)} TRIMESTRES\")\n",
    "    print(f\"===========================================================\")\n",
    "\n",
    "    # Bucle principal para procesar cada trimestre\n",
    "    for year, quarter in periodos:\n",
    "        \n",
    "        df_nacional, df_estatal = procesar_trimestre_enoe(year, quarter)\n",
    "        \n",
    "        if df_nacional is not None and df_estatal is not None:\n",
    "            resultados_nacionales.append(df_nacional)\n",
    "            resultados_estatales.append(df_estatal)\n",
    "        else:\n",
    "            # Manejo explícito de trimestres sin datos (se añade una fila con NA)\n",
    "            # Esto se asegura de mantener la continuidad de la serie de tiempo.\n",
    "            periodo_na = {'year': year, 'quarter': quarter}\n",
    "            \n",
    "            # Serie Nacional con NA\n",
    "            serie_na_nacional = pd.Series(periodo_na)\n",
    "            # Se añaden las columnas faltantes (variables calculadas) con NaN\n",
    "            if resultados_nacionales:\n",
    "                # Usar la estructura de la primera serie de tiempo para rellenar los NaNs\n",
    "                for col in resultados_nacionales[0].index:\n",
    "                    if col not in serie_na_nacional:\n",
    "                         serie_na_nacional[col] = np.nan\n",
    "            resultados_nacionales.append(serie_na_nacional)\n",
    "            \n",
    "            # DataFrame Estatal con NA\n",
    "            df_na_estatal = pd.DataFrame(periodo_na, index=range(1, 33)) # 32 estados\n",
    "            df_na_estatal['ent_code'] = df_na_estatal.index\n",
    "            df_na_estatal['ent_nombre'] = df_na_estatal['ent_code'].map(ENTIDADES)\n",
    "            # Rellenar todas las columnas de variables con NaN\n",
    "            if resultados_estatales:\n",
    "                 # Usar la estructura del primer DataFrame estatal para rellenar los NaNs\n",
    "                for col in resultados_estatales[0].columns:\n",
    "                    if col not in df_na_estatal.columns:\n",
    "                        df_na_estatal[col] = np.nan\n",
    "            resultados_estatales.append(df_na_estatal)\n",
    "            \n",
    "            print(f\"--- 🚫 Se agregó NA/NaN para {year} T{quarter} y se prosigue. ---\")\n",
    "            \n",
    "\n",
    "    # --- 6. CONSOLIDACIÓN DE BASES DE DATOS ---\n",
    "\n",
    "    # 1. Serie de Tiempo Nacional\n",
    "    df_serie_nacional = pd.DataFrame(resultados_nacionales).reset_index(drop=True)\n",
    "    df_serie_nacional['periodo'] = df_serie_nacional['year'].astype(str) + '-T' + df_serie_nacional['quarter'].astype(str)\n",
    "    df_serie_nacional.set_index('periodo', inplace=True)\n",
    "\n",
    "    print(\"\\n===========================================================\")\n",
    "    print(\"      ✅ BASE DE SERIE DE TIEMPO NACIONAL CREADA\")\n",
    "    print(\"      (Incluye nuevos indicadores estratégicos)\")\n",
    "    print(\"===========================================================\")\n",
    "    print(df_serie_nacional.head())\n",
    "    # Opcional: df_serie_nacional.to_csv(\"serie_tiempo_nacional_estrat.csv\")\n",
    "\n",
    "\n",
    "    # 2. Serie de Tiempo Estatal\n",
    "    df_serie_estatal = pd.concat(resultados_estatales, ignore_index=True)\n",
    "    df_serie_estatal['periodo'] = df_serie_estatal['year'].astype(str) + '-T' + df_serie_estatal['quarter'].astype(str)\n",
    "    \n",
    "    print(\"\\n===========================================================\")\n",
    "    print(\"      ✅ BASE DE SERIE DE TIEMPO ESTATAL CREADA\")\n",
    "    print(\"      (Incluye nuevos indicadores estratégicos)\")\n",
    "    print(\"===========================================================\")\n",
    "    print(df_serie_estatal.head())\n",
    "    # Opcional: df_serie_estatal.to_csv(\"serie_tiempo_estatal_estrat.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
