{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36eb162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo A√±adir deflactor del PIB trimestral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2007bc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ‚ö†Ô∏è Saltando periodo 2020 T2 (No disponible o no oficial). ---\n",
      "--- ‚ö†Ô∏è Saltando periodo 2020 T3 (No disponible o no oficial). ---\n",
      "\n",
      "===========================================================\n",
      "  INICIANDO PROCESAMIENTO DE 26 TRIMESTRES\n",
      "  Rango: 2018 T1 hasta 2024 T4\n",
      "===========================================================\n",
      "\n",
      "--- ‚è≥ Procesando: 2018 T1 ---\n",
      "‚ùå Error Cr√≠tico: Archivo no encontrado en: data\\ENOE_dta\\ENOE_2018_1\\ENOE_SDEMT118.dta\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2018 T1 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2018 T2 ---\n",
      "‚ùå Error Cr√≠tico: Archivo no encontrado en: data\\ENOE_dta\\ENOE_2018_2\\ENOE_SDEMT218.dta\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2018 T2 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2018 T3 ---\n",
      "‚ùå Error Cr√≠tico: Archivo no encontrado en: data\\ENOE_dta\\ENOE_2018_3\\ENOE_SDEMT318.dta\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2018 T3 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2018 T4 ---\n",
      "‚ùå Error Cr√≠tico: Archivo no encontrado en: data\\ENOE_dta\\ENOE_2018_4\\ENOE_SDEMT418.dta\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2018 T4 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2019 T1 ---\n",
      "‚ùå Error Cr√≠tico: Archivo no encontrado en: data\\ENOE_dta\\ENOE_2019_1\\ENOE_SDEMT119.dta\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2019 T1 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2019 T2 ---\n",
      "‚ùå Error Cr√≠tico: Archivo no encontrado en: data\\ENOE_dta\\ENOE_2019_2\\ENOE_SDEMT219.dta\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2019 T2 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2019 T3 ---\n",
      "‚ùå Error Cr√≠tico: Archivo no encontrado en: data\\ENOE_dta\\ENOE_2019_3\\ENOE_SDEMT319.dta\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2019 T3 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2019 T4 ---\n",
      "‚ùå Error Cr√≠tico: Archivo no encontrado en: data\\ENOE_dta\\ENOE_2019_4\\ENOE_SDEMT419.dta\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2019 T4 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2020 T1 ---\n",
      "‚ùå Error Cr√≠tico: Archivo no encontrado en: data\\ENOE_dta\\ENOE_2020_1\\ENOE_SDEMT120.dta\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2020 T1 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2020 T4 ---\n",
      "‚ùå Error Cr√≠tico: Archivo no encontrado en: data\\ENOE_dta\\ENOE_2020_4\\ENOE_SDEMT420.dta\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2020 T4 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2021 T1 ---\n",
      "‚ùå Error Cr√≠tico: Archivo no encontrado en: data\\ENOE_dta\\ENOE_2021_1\\ENOE_SDEMT121.dta\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2021 T1 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2021 T2 ---\n",
      "‚ùå Error Cr√≠tico: Archivo no encontrado en: data\\ENOE_dta\\ENOE_2021_2\\ENOE_SDEMT221.dta\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2021 T2 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2021 T3 ---\n",
      "‚ùå Error Cr√≠tico: Archivo no encontrado en: data\\ENOE_dta\\ENOE_2021_3\\ENOE_SDEMT321.dta\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2021 T3 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2021 T4 ---\n",
      "‚ùå Error Cr√≠tico: Archivo no encontrado en: data\\ENOE_dta\\ENOE_2021_4\\ENOE_SDEMT421.dta\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2021 T4 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2022 T1 ---\n",
      "‚ùå Error Cr√≠tico: Archivo no encontrado en: data\\ENOE_dta\\ENOE_2022_1\\ENOE_SDEMT122.dta\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2022 T1 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2022 T2 ---\n",
      "‚ùå Error Cr√≠tico: Archivo no encontrado en: data\\ENOE_dta\\ENOE_2022_2\\ENOE_SDEMT222.dta\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2022 T2 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2022 T3 ---\n",
      "‚ùå Error Cr√≠tico: Archivo no encontrado en: data\\ENOE_dta\\ENOE_2022_3\\ENOE_SDEMT322.dta\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2022 T3 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2022 T4 ---\n",
      "‚ùå Error Cr√≠tico: Archivo no encontrado en: data\\ENOE_dta\\ENOE_2022_4\\ENOE_SDEMT422.dta\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2022 T4 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2023 T1 ---\n",
      "‚úÖ Archivo cargado exitosamente. 450,263 registros.\n",
      "\n",
      "--- ‚è≥ Procesando: 2023 T2 ---\n",
      "‚úÖ Archivo cargado exitosamente. 431,149 registros.\n",
      "\n",
      "--- ‚è≥ Procesando: 2023 T3 ---\n",
      "‚úÖ Archivo cargado exitosamente. 429,077 registros.\n",
      "\n",
      "--- ‚è≥ Procesando: 2023 T4 ---\n",
      "‚úÖ Archivo cargado exitosamente. 419,983 registros.\n",
      "\n",
      "--- ‚è≥ Procesando: 2024 T1 ---\n",
      "‚úÖ Archivo cargado exitosamente. 423,866 registros.\n",
      "\n",
      "--- ‚è≥ Procesando: 2024 T2 ---\n",
      "‚úÖ Archivo cargado exitosamente. 427,123 registros.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 226\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# Bucle principal para procesar cada trimestre\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year, quarter \u001b[38;5;129;01min\u001b[39;00m periodos:\n\u001b[1;32m--> 226\u001b[0m     df_nacional, df_estatal \u001b[38;5;241m=\u001b[39m \u001b[43mprocesar_trimestre_enoe\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquarter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df_nacional \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m df_estatal \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m         resultados_nacionales\u001b[38;5;241m.\u001b[39mappend(df_nacional)\n",
      "Cell \u001b[1;32mIn[1], line 163\u001b[0m, in \u001b[0;36mprocesar_trimestre_enoe\u001b[1;34m(year, quarter, file_format)\u001b[0m\n\u001b[0;32m    161\u001b[0m df_base_est \u001b[38;5;241m=\u001b[39m df_base[df_base[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m ent_code]\n\u001b[0;32m    162\u001b[0m df_15_y_mas_est \u001b[38;5;241m=\u001b[39m df_15_y_mas[df_15_y_mas[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m ent_code]\n\u001b[1;32m--> 163\u001b[0m df_pea_est \u001b[38;5;241m=\u001b[39m \u001b[43mdf_pea\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_pea\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ment_code\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    164\u001b[0m df_ocupada_est \u001b[38;5;241m=\u001b[39m df_ocupada[df_ocupada[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m ent_code]\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# Recolecci√≥n de datos\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rodri\\anaconda3\\envs\\gee\\Lib\\site-packages\\pandas\\core\\frame.py:4098\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4096\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   4097\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 4098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   4101\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   4102\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32mc:\\Users\\rodri\\anaconda3\\envs\\gee\\Lib\\site-packages\\pandas\\core\\frame.py:4160\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   4159\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 4160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rodri\\anaconda3\\envs\\gee\\Lib\\site-packages\\pandas\\core\\generic.py:4172\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   4161\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   4162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   4163\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4164\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   4165\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4170\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   4171\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4172\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4173\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   4174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32mc:\\Users\\rodri\\anaconda3\\envs\\gee\\Lib\\site-packages\\pandas\\core\\generic.py:4152\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   4147\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[0;32m   4148\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[0;32m   4149\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[0;32m   4150\u001b[0m     )\n\u001b[1;32m-> 4152\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4154\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4156\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4158\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4159\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\rodri\\anaconda3\\envs\\gee\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rodri\\anaconda3\\envs\\gee\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:687\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32mc:\\Users\\rodri\\anaconda3\\envs\\gee\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:688\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 688\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n\u001b[0;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32mc:\\Users\\rodri\\anaconda3\\envs\\gee\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1373\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1370\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m-> 1373\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m   1380\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m   1381\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rodri\\anaconda3\\envs\\gee\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rodri\\anaconda3\\envs\\gee\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[1;32m--> 162\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[0;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict # √ötil para recolectar datos a nivel estatal\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# FUNCIONES DE UTILIDAD\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def weighted_average(df, value_col, weight_col):\n",
    "    \"\"\"Calcula el promedio ponderado de una columna usando pesos (factores de expansi√≥n).\"\"\"\n",
    "    # Asegura que las columnas de valor y peso existan y no sean NaN\n",
    "    df_filtered = df.dropna(subset=[value_col, weight_col])\n",
    "    \n",
    "    # Maneja el caso de que no haya datos o la suma de pesos sea cero\n",
    "    if df_filtered.empty or df_filtered[weight_col].sum() == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # Excluir valores negativos o cero si se asume que 'ingocup' es ingreso positivo\n",
    "    # if value_col in ['ingocup', 'ing_x_hrs']:\n",
    "    #     df_filtered = df_filtered[df_filtered[value_col] > 0]\n",
    "    \n",
    "    return np.average(df_filtered[value_col], weights=df_filtered[weight_col])\n",
    "\n",
    "# Diccionario de Entidades para mapear c√≥digos a nombres\n",
    "ENTIDADES = {\n",
    "    1: 'Aguascalientes', 2: 'Baja California', 3: 'Baja California Sur', 4: 'Campeche',\n",
    "    5: 'Coahuila', 6: 'Colima', 7: 'Chiapas', 8: 'Chihuahua', 9: 'Ciudad de M√©xico',\n",
    "    10: 'Durango', 11: 'Guanajuato', 12: 'Guerrero', 13: 'Hidalgo', 14: 'Jalisco',\n",
    "    15: 'M√©xico', 16: 'Michoac√°n', 17: 'Morelos', 18: 'Nayarit', 19: 'Nuevo Le√≥n',\n",
    "    20: 'Oaxaca', 21: 'Puebla', 22: 'Quer√©taro', 23: 'Quintana Roo', 24: 'San Luis Potos√≠',\n",
    "    25: 'Sinaloa', 26: 'Sonora', 27: 'Tabasco', 28: 'Tamaulipas', 29: 'Tlaxcala',\n",
    "    30: 'Veracruz', 31: 'Yucat√°n', 32: 'Zacatecas'\n",
    "}\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# FUNCI√ìN PRINCIPAL DE PROCESAMIENTO TRIMESTRAL\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def procesar_trimestre_enoe(year, quarter, file_format='dta'):\n",
    "    \"\"\"\n",
    "    Carga, limpia y calcula indicadores clave a nivel nacional y estatal \n",
    "    para un trimestre espec√≠fico.\n",
    "    \n",
    "    Args:\n",
    "        year (int): El a√±o del trimestre a analizar (e.g., 2023).\n",
    "        quarter (int): El n√∫mero de trimestre (1, 2, 3, 4).\n",
    "        file_format (str): Formato del archivo ('dta' o 'csv').\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (pd.Series Nacional, pd.DataFrame Estatal) con los indicadores, \n",
    "               o (None, None) si el archivo no se encuentra o est√° vac√≠o.\n",
    "    \"\"\"\n",
    "    periodo_str = f\"{year} T{quarter}\"\n",
    "    print(f\"\\n--- ‚è≥ Procesando: {periodo_str} ---\")\n",
    "\n",
    "    # --- 1. Construcci√≥n de la Ruta del Archivo ---\n",
    "    year_short = str(year)[-2:]\n",
    "    dir_name = f\"ENOE_{year}_{quarter}\"\n",
    "    file_name = f\"ENOE_SDEMT{quarter}{year_short}.{file_format}\"\n",
    "    file_path = os.path.join(\"data\", f\"ENOE_{file_format}\", dir_name, file_name)\n",
    "    \n",
    "    # --- 2. Carga de Datos y Manejo de Errores (Debugging) ---\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"‚ùå Error Cr√≠tico: Archivo no encontrado en: {file_path}\")\n",
    "        return None, None # Retorna None para el control en el script principal\n",
    "    \n",
    "    try:\n",
    "        if file_format == 'dta':\n",
    "            df = pd.read_stata(file_path, convert_categoricals=False)\n",
    "        elif file_format == 'csv':\n",
    "            df = pd.read_csv(file_path)\n",
    "        else:\n",
    "            raise ValueError(\"Formato de archivo no soportado.\")\n",
    "        \n",
    "        if df.empty:\n",
    "            print(f\"‚ùå Error de Carga: Archivo encontrado, pero vac√≠o: {file_path}\")\n",
    "            return None, None\n",
    "            \n",
    "        print(f\"‚úÖ Archivo cargado exitosamente. {len(df):,} registros.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Ocurri√≥ un error de lectura de datos: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # --- 3. Limpieza y Preparaci√≥n de Datos ---\n",
    "    # Conversi√≥n de tipos de datos esenciales\n",
    "    df['r_def'] = df['r_def'].astype(str).str.strip()\n",
    "    \n",
    "    columnas_numericas = [\n",
    "        'fac_tri', 'sex', 'eda', 'clase1', 'clase2', 'c_res',\n",
    "        'ingocup', 'ing_x_hrs', 'ent'\n",
    "    ]\n",
    "    for col in columnas_numericas:\n",
    "        # Usamos errors='coerce' para convertir valores no num√©ricos a NaN\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # Filtro base: Universo de residentes con entrevista completa (r_def='00', c_res=1 o 3)\n",
    "    df_base = df[(df['r_def'] == '0.0') & (df['c_res'].isin([1, 3]))].copy()\n",
    "    \n",
    "    if df_base.empty:\n",
    "        print(\"‚ùå Error de Filtro: No se encontraron registros v√°lidos despu√©s del filtro base.\")\n",
    "        return None, None\n",
    "\n",
    "    # Filtro de Poblaci√≥n en Edad de Trabajar (PET): 15 a√±os y m√°s\n",
    "    df_15_y_mas = df_base[df_base['eda'].between(15, 98)].copy()\n",
    "    \n",
    "    # Definici√≥n de subconjuntos\n",
    "    df_pea = df_15_y_mas[df_15_y_mas['clase1'] == 1].copy()      # PEA (clase1=1)\n",
    "    df_ocupada = df_15_y_mas[df_15_y_mas['clase2'] == 1].copy()  # Ocupada (clase2=1)\n",
    "    \n",
    "    # Asignaci√≥n de nombres de estado (Necesario para ambos niveles)\n",
    "    df_base['ent_nombre'] = df_base['ent'].map(ENTIDADES)\n",
    "    df_15_y_mas['ent_nombre'] = df_15_y_mas['ent'].map(ENTIDADES)\n",
    "    df_pea['ent_nombre'] = df_pea['ent'].map(ENTIDADES)\n",
    "    df_ocupada['ent_nombre'] = df_ocupada['ent'].map(ENTIDADES)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # --- 4. C√ÅLCULOS A NIVEL NACIONAL ---\n",
    "    # ------------------------------------------------------------------\n",
    "    \n",
    "    datos_nacional = {\n",
    "        # Identificadores de Tiempo\n",
    "        'year': year,\n",
    "        'quarter': quarter,\n",
    "        \n",
    "        # Poblaci√≥n Total\n",
    "        'pob_total': df_base['fac_tri'].sum(),\n",
    "        'pob_hombres_total': df_base[df_base['sex'] == 1]['fac_tri'].sum(),\n",
    "        'pob_mujeres_total': df_base[df_base['sex'] == 2]['fac_tri'].sum(),\n",
    "        \n",
    "        # PET (15 a√±os y m√°s)\n",
    "        'pet_total': df_15_y_mas['fac_tri'].sum(),\n",
    "        'pet_hombres_15mas': df_15_y_mas[df_15_y_mas['sex'] == 1]['fac_tri'].sum(),\n",
    "        'pet_mujeres_15mas': df_15_y_mas[df_15_y_mas['sex'] == 2]['fac_tri'].sum(),\n",
    "\n",
    "        # PEA\n",
    "        'pea_total': df_pea['fac_tri'].sum(),\n",
    "        'pea_hombres': df_pea[df_pea['sex'] == 1]['fac_tri'].sum(),\n",
    "        'pea_mujeres': df_pea[df_pea['sex'] == 2]['fac_tri'].sum(),\n",
    "        \n",
    "        # Ingreso Promedio\n",
    "        'ing_prom_mes_total': weighted_average(df_ocupada, 'ingocup', 'fac_tri'),\n",
    "        'ing_prom_mes_hombres': weighted_average(df_ocupada[df_ocupada['sex'] == 1], 'ingocup', 'fac_tri'),\n",
    "        'ing_prom_mes_mujeres': weighted_average(df_ocupada[df_ocupada['sex'] == 2], 'ingocup', 'fac_tri'),\n",
    "        \n",
    "        'ing_prom_hora_total': weighted_average(df_ocupada, 'ing_x_hrs', 'fac_tri'),\n",
    "        'ing_prom_hora_hombres': weighted_average(df_ocupada[df_ocupada['sex'] == 1], 'ing_x_hrs', 'fac_tri'),\n",
    "        'ing_prom_hora_mujeres': weighted_average(df_ocupada[df_ocupada['sex'] == 2], 'ing_x_hrs', 'fac_tri'),\n",
    "    }\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # --- 5. C√ÅLCULOS A NIVEL ESTATAL ---\n",
    "    # ------------------------------------------------------------------\n",
    "    \n",
    "    # Inicializaci√≥n de un diccionario de listas para recolectar datos por estado\n",
    "    datos_estatal = defaultdict(list)\n",
    "    \n",
    "    for ent_code, ent_name in ENTIDADES.items():\n",
    "        # Filtros por Estado\n",
    "        df_base_est = df_base[df_base['ent'] == ent_code]\n",
    "        df_15_y_mas_est = df_15_y_mas[df_15_y_mas['ent'] == ent_code]\n",
    "        df_pea_est = df_pea[df_pea['ent'] == ent_code]\n",
    "        df_ocupada_est = df_ocupada[df_ocupada['ent'] == ent_code]\n",
    "        \n",
    "        # Recolecci√≥n de datos\n",
    "        datos_estatal['year'].append(year)\n",
    "        datos_estatal['quarter'].append(quarter)\n",
    "        datos_estatal['ent_code'].append(ent_code)\n",
    "        datos_estatal['ent_nombre'].append(ent_name)\n",
    "        \n",
    "        # Poblaci√≥n Total\n",
    "        datos_estatal['pob_total'].append(df_base_est['fac_tri'].sum())\n",
    "        datos_estatal['pob_hombres_total'].append(df_base_est[df_base_est['sex'] == 1]['fac_tri'].sum())\n",
    "        datos_estatal['pob_mujeres_total'].append(df_base_est[df_base_est['sex'] == 2]['fac_tri'].sum())\n",
    "\n",
    "        # PET (15 a√±os y m√°s)\n",
    "        datos_estatal['pet_hombres_15mas'].append(df_15_y_mas_est[df_15_y_mas_est['sex'] == 1]['fac_tri'].sum())\n",
    "        datos_estatal['pet_mujeres_15mas'].append(df_15_y_mas_est[df_15_y_mas_est['sex'] == 2]['fac_tri'].sum())\n",
    "\n",
    "        # PEA\n",
    "        datos_estatal['pea_hombres'].append(df_pea_est[df_pea_est['sex'] == 1]['fac_tri'].sum())\n",
    "        datos_estatal['pea_mujeres'].append(df_pea_est[df_pea_est['sex'] == 2]['fac_tri'].sum())\n",
    "        \n",
    "        # Ingreso Promedio\n",
    "        datos_estatal['ing_prom_mes_total'].append(weighted_average(df_ocupada_est, 'ingocup', 'fac_tri'))\n",
    "        datos_estatal['ing_prom_hora_total'].append(weighted_average(df_ocupada_est, 'ing_x_hrs', 'fac_tri'))\n",
    "\n",
    "    # Convierte el diccionario recolectado a un DataFrame\n",
    "    df_estatal_trimestre = pd.DataFrame(datos_estatal)\n",
    "    \n",
    "    return pd.Series(datos_nacional), df_estatal_trimestre\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# EJECUCI√ìN DEL SCRIPT Y CONSOLIDACI√ìN DE SERIES DE TIEMPO\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- RANGO DE AN√ÅLISIS ---\n",
    "    # Define el rango de a√±os y trimestres a analizar\n",
    "    START_YEAR = 2018\n",
    "    END_YEAR = 2024\n",
    "    \n",
    "    # Lista para almacenar los resultados nacionales (Series de Pandas)\n",
    "    resultados_nacionales = []\n",
    "    # Lista para almacenar los resultados estatales (DataFrames)\n",
    "    resultados_estatales = []\n",
    "\n",
    "    # Genera la secuencia de trimestres\n",
    "    periodos = []\n",
    "    for y in range(START_YEAR, END_YEAR + 1):\n",
    "        for q in range(1, 5):\n",
    "            # Condici√≥n para saltarse trimestres no disponibles (ej. 2020 T2 y T3)\n",
    "            if y == 2020 and q in [2, 3]:\n",
    "                print(f\"--- ‚ö†Ô∏è Saltando periodo {y} T{q} (No disponible o no oficial). ---\")\n",
    "                continue\n",
    "            periodos.append((y, q))\n",
    "\n",
    "    print(f\"\\n===========================================================\")\n",
    "    print(f\"  INICIANDO PROCESAMIENTO DE {len(periodos)} TRIMESTRES\")\n",
    "    print(f\"  Rango: {START_YEAR} T1 hasta {END_YEAR} T4\")\n",
    "    print(f\"===========================================================\")\n",
    "\n",
    "    # Bucle principal para procesar cada trimestre\n",
    "    for year, quarter in periodos:\n",
    "        df_nacional, df_estatal = procesar_trimestre_enoe(year, quarter)\n",
    "        \n",
    "        if df_nacional is not None and df_estatal is not None:\n",
    "            resultados_nacionales.append(df_nacional)\n",
    "            resultados_estatales.append(df_estatal)\n",
    "        else:\n",
    "            # Manejo expl√≠cito de trimestres sin datos (se a√±ade una fila con NA)\n",
    "            periodo_na = {'year': year, 'quarter': quarter}\n",
    "            \n",
    "            # Series Nacional con NA\n",
    "            serie_na_nacional = pd.Series(periodo_na)\n",
    "            resultados_nacionales.append(serie_na_nacional)\n",
    "            \n",
    "            # DataFrame Estatal con NA\n",
    "            df_na_estatal = pd.DataFrame(periodo_na, index=range(1, 33)) # 32 estados\n",
    "            df_na_estatal['ent_code'] = df_na_estatal.index\n",
    "            df_na_estatal['ent_nombre'] = df_na_estatal['ent_code'].map(ENTIDADES)\n",
    "            # Rellenar todas las columnas de variables con NaN\n",
    "            for col in resultados_estatales[0].columns if resultados_estatales else []:\n",
    "                if col not in df_na_estatal.columns:\n",
    "                    df_na_estatal[col] = np.nan\n",
    "            resultados_estatales.append(df_na_estatal)\n",
    "            \n",
    "            print(f\"--- üö´ Se agreg√≥ NA/NaN para {year} T{quarter} y se prosigue. ---\")\n",
    "            \n",
    "\n",
    "    # --- 6. CONSOLIDACI√ìN DE BASES DE DATOS ---\n",
    "\n",
    "    # 1. Serie de Tiempo Nacional\n",
    "    df_serie_nacional = pd.DataFrame(resultados_nacionales).reset_index(drop=True)\n",
    "    # Crea un √≠ndice de tiempo para facilitar el an√°lisis\n",
    "    df_serie_nacional['periodo'] = df_serie_nacional['year'].astype(str) + '-T' + df_serie_nacional['quarter'].astype(str)\n",
    "    df_serie_nacional.set_index('periodo', inplace=True)\n",
    "\n",
    "    print(\"\\n===========================================================\")\n",
    "    print(\"      ‚úÖ BASE DE SERIE DE TIEMPO NACIONAL CREADA\")\n",
    "    print(\"===========================================================\")\n",
    "    print(df_serie_nacional.head())\n",
    "    df_serie_nacional.to_csv(\"Resultados/serie_tiempo_nacional.csv\")\n",
    "\n",
    "\n",
    "    # 2. Serie de Tiempo Estatal\n",
    "    df_serie_estatal = pd.concat(resultados_estatales, ignore_index=True)\n",
    "    # Crea un √≠ndice de tiempo\n",
    "    df_serie_estatal['periodo'] = df_serie_estatal['year'].astype(str) + '-T' + df_serie_estatal['quarter'].astype(str)\n",
    "    \n",
    "    print(\"\\n===========================================================\")\n",
    "    print(\"      ‚úÖ BASE DE SERIE DE TIEMPO ESTATAL CREADA\")\n",
    "    print(\"===========================================================\")\n",
    "    print(df_serie_estatal.head())\n",
    "    df_serie_estatal.to_csv(\"Resultados/serie_tiempo_estatal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b07800",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_stata(\"Data\\ENOE_dta\\ENOE_2005_1\\SDEMT105.dta\", convert_categoricals= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ace9c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r_def</th>\n",
       "      <th>loc</th>\n",
       "      <th>mun</th>\n",
       "      <th>est</th>\n",
       "      <th>est_d</th>\n",
       "      <th>ageb</th>\n",
       "      <th>t_loc</th>\n",
       "      <th>cd_a</th>\n",
       "      <th>ent</th>\n",
       "      <th>con</th>\n",
       "      <th>...</th>\n",
       "      <th>ma48me1sm</th>\n",
       "      <th>p14apoyos</th>\n",
       "      <th>scian</th>\n",
       "      <th>t_tra</th>\n",
       "      <th>emp_ppal</th>\n",
       "      <th>tue_ppal</th>\n",
       "      <th>trans_ppal</th>\n",
       "      <th>mh_fil2</th>\n",
       "      <th>mh_col</th>\n",
       "      <th>sec_ins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6040.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6040.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6040.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424005</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6040.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424006</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6040.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>424007 rows √ó 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        r_def  loc  mun   est est_d  ageb t_loc  cd_a   ent     con  ...  \\\n",
       "0         0.0  NaN  3.0  24.0  0005   0.0     1   1.0   9.0   502.0  ...   \n",
       "1         0.0  NaN  3.0  24.0  0005   0.0     1   1.0   9.0   502.0  ...   \n",
       "2         0.0  NaN  3.0  24.0  0005   0.0     1   1.0   9.0   502.0  ...   \n",
       "3         0.0  NaN  7.0  33.0  0008   0.0     1   1.0   9.0   506.0  ...   \n",
       "4         0.0  NaN  7.0  33.0  0008   0.0     1   1.0   9.0   506.0  ...   \n",
       "...       ...  ...  ...   ...   ...   ...   ...   ...   ...     ...  ...   \n",
       "424002    0.0  NaN  NaN  22.0  0888   0.0     4  86.0  32.0  6040.0  ...   \n",
       "424003    0.0  NaN  NaN  22.0  0888   0.0     4  86.0  32.0  6040.0  ...   \n",
       "424004    0.0  NaN  NaN  22.0  0888   0.0     4  86.0  32.0  6040.0  ...   \n",
       "424005    0.0  NaN  NaN  22.0  0888   0.0     4  86.0  32.0  6040.0  ...   \n",
       "424006    0.0  NaN  NaN  22.0  0888   0.0     4  86.0  32.0  6040.0  ...   \n",
       "\n",
       "        ma48me1sm  p14apoyos  scian  t_tra  emp_ppal  tue_ppal  trans_ppal  \\\n",
       "0             0.0        0.0    0.0    0.0       0.0       0.0         0.0   \n",
       "1             0.0        2.0    0.0    1.0       0.0       0.0         0.0   \n",
       "2             0.0        2.0    0.0    1.0       0.0       0.0         0.0   \n",
       "3             0.0        2.0   19.0    1.0       1.0       1.0         0.0   \n",
       "4             0.0        2.0    5.0    1.0       1.0       2.0         0.0   \n",
       "...           ...        ...    ...    ...       ...       ...         ...   \n",
       "424002        1.0        2.0    1.0    1.0       1.0       2.0         0.0   \n",
       "424003        0.0        1.0    0.0    1.0       0.0       0.0         0.0   \n",
       "424004        0.0        0.0    0.0    0.0       0.0       0.0         0.0   \n",
       "424005        0.0        1.0    0.0    1.0       0.0       0.0         0.0   \n",
       "424006        0.0        1.0    0.0    1.0       0.0       0.0         0.0   \n",
       "\n",
       "        mh_fil2  mh_col  sec_ins  \n",
       "0           0.0     0.0      0.0  \n",
       "1           0.0     0.0      0.0  \n",
       "2           0.0     0.0      0.0  \n",
       "3           1.0     1.0      8.0  \n",
       "4           3.0     1.0      4.0  \n",
       "...         ...     ...      ...  \n",
       "424002      4.0     1.0      3.0  \n",
       "424003      0.0     0.0      0.0  \n",
       "424004      0.0     0.0      0.0  \n",
       "424005      0.0     0.0      0.0  \n",
       "424006      0.0     0.0      0.0  \n",
       "\n",
       "[424007 rows x 104 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "288997d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['r_def', 'loc', 'mun', 'est', 'est_d', 'ageb', 't_loc', 'cd_a', 'ent',\n",
       "       'con',\n",
       "       ...\n",
       "       'ma48me1sm', 'p14apoyos', 'scian', 't_tra', 'emp_ppal', 'tue_ppal',\n",
       "       'trans_ppal', 'mh_fil2', 'mh_col', 'sec_ins'],\n",
       "      dtype='object', length=104)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf7bb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Definici√≥n del Rango de la Serie de Tiempo ---\n",
      "--- ‚ö†Ô∏è Saltando periodo 2020 T2 (No disponible o no oficial). ---\n",
      "--- ‚ö†Ô∏è Saltando periodo 2020 T3 (No disponible o no oficial). ---\n",
      "\n",
      "===========================================================\n",
      "  INICIANDO PROCESAMIENTO DE 80 TRIMESTRES\n",
      "===========================================================\n",
      "\n",
      "--- ‚è≥ Procesando: 2005 T1 ---\n",
      "‚úÖ Archivo cargado exitosamente. 424,007 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2005 T1 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2005 T2 ---\n",
      "‚úÖ Archivo cargado exitosamente. 428,727 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2005 T2 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2005 T3 ---\n",
      "‚úÖ Archivo cargado exitosamente. 421,751 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2005 T3 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2005 T4 ---\n",
      "‚úÖ Archivo cargado exitosamente. 423,757 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2005 T4 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2006 T1 ---\n",
      "‚úÖ Archivo cargado exitosamente. 426,160 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2006 T1 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2006 T2 ---\n",
      "‚úÖ Archivo cargado exitosamente. 424,579 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2006 T2 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2006 T3 ---\n",
      "‚úÖ Archivo cargado exitosamente. 423,305 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2006 T3 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2006 T4 ---\n",
      "‚úÖ Archivo cargado exitosamente. 421,581 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2006 T4 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2007 T1 ---\n",
      "‚úÖ Archivo cargado exitosamente. 423,910 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2007 T1 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2007 T2 ---\n",
      "‚úÖ Archivo cargado exitosamente. 422,591 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2007 T2 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2007 T3 ---\n",
      "‚úÖ Archivo cargado exitosamente. 418,327 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2007 T3 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2007 T4 ---\n",
      "‚úÖ Archivo cargado exitosamente. 409,422 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2007 T4 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2008 T1 ---\n",
      "‚úÖ Archivo cargado exitosamente. 416,538 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2008 T1 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2008 T2 ---\n",
      "‚úÖ Archivo cargado exitosamente. 415,610 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2008 T2 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2008 T3 ---\n",
      "‚úÖ Archivo cargado exitosamente. 410,219 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2008 T3 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2008 T4 ---\n",
      "‚úÖ Archivo cargado exitosamente. 407,232 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2008 T4 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2009 T1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\AppData\\Local\\Temp\\ipykernel_1416\\43258366.py:140: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  df = pd.read_stata(file_path, convert_categoricals=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo cargado exitosamente. 407,725 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2009 T1 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2009 T2 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\AppData\\Local\\Temp\\ipykernel_1416\\43258366.py:140: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  df = pd.read_stata(file_path, convert_categoricals=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo cargado exitosamente. 405,529 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2009 T2 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2009 T3 ---\n",
      "‚úÖ Archivo cargado exitosamente. 402,919 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2009 T3 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2009 T4 ---\n",
      "‚úÖ Archivo cargado exitosamente. 403,862 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2009 T4 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2010 T1 ---\n",
      "‚úÖ Archivo cargado exitosamente. 406,797 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2010 T1 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2010 T2 ---\n",
      "‚úÖ Archivo cargado exitosamente. 408,164 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2010 T2 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2010 T3 ---\n",
      "‚úÖ Archivo cargado exitosamente. 405,533 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2010 T3 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2010 T4 ---\n",
      "‚úÖ Archivo cargado exitosamente. 401,524 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2010 T4 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2011 T1 ---\n",
      "‚úÖ Archivo cargado exitosamente. 402,117 registros. Ponderador: FAC\n",
      "‚ùå Error Cr√≠tico: Columna de ponderador 'FAC' no encontrada.\n",
      "--- üö´ Se agreg√≥ NA/NaN para 2011 T1 y se prosigue. ---\n",
      "\n",
      "--- ‚è≥ Procesando: 2011 T2 ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# FUNCIONES DE UTILIDAD\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def weighted_average(df, value_col, weight_col):\n",
    "    \"\"\"Calcula el promedio ponderado de una columna usando pesos (factores de expansi√≥n).\"\"\"\n",
    "    df_filtered = df.dropna(subset=[value_col, weight_col])\n",
    "    \n",
    "    # Excluir valores de ingreso no v√°lidos (generalmente negativos o no especificados, si se aplica)\n",
    "    if value_col in ['ingocup', 'ing_x_hrs']:\n",
    "        df_filtered = df_filtered[df_filtered[value_col] > 0].copy()\n",
    "    \n",
    "    if df_filtered.empty or df_filtered[weight_col].sum() == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    return np.average(df_filtered[value_col], weights=df_filtered[weight_col])\n",
    "\n",
    "# Diccionario de Entidades para mapear c√≥digos a nombres\n",
    "ENTIDADES = {\n",
    "    1: 'Aguascalientes', 2: 'Baja California', 3: 'Baja California Sur', 4: 'Campeche',\n",
    "    5: 'Coahuila', 6: 'Colima', 7: 'Chiapas', 8: 'Chihuahua', 9: 'Ciudad de M√©xico',\n",
    "    10: 'Durango', 11: 'Guanajuato', 12: 'Guerrero', 13: 'Hidalgo', 14: 'Jalisco',\n",
    "    15: 'M√©xico', 16: 'Michoac√°n', 17: 'Morelos', 18: 'Nayarit', 19: 'Nuevo Le√≥n',\n",
    "    20: 'Oaxaca', 21: 'Puebla', 22: 'Quer√©taro', 23: 'Quintana Roo', 24: 'San Luis Potos√≠',\n",
    "    25: 'Sinaloa', 26: 'Sonora', 27: 'Tabasco', 28: 'Tamaulipas', 29: 'Tlaxcala',\n",
    "    30: 'Veracruz', 31: 'Yucat√°n', 32: 'Zacatecas'\n",
    "}\n",
    "\n",
    "def obtener_nombre_archivo(year, quarter, file_format='dta'):\n",
    "    \"\"\"Determina el nombre del archivo SDEMT seg√∫n el periodo.\"\"\"\n",
    "    year_short = str(year)[-2:]\n",
    "    \n",
    "    # Periodo 1: 2005 T1 a 2018 T4 (May√∫sculas)\n",
    "    if year <= 2018:\n",
    "        base_name = f\"SDEMT{quarter}{year_short}\".upper()\n",
    "    \n",
    "    # Periodo 2: 2019 T1 a 2019 T4 (Min√∫sculas)\n",
    "    elif year == 2019:\n",
    "        base_name = f\"sdemt{quarter}{year_short}\".lower()\n",
    "    \n",
    "    # Periodo 3: 2020 T3 a 2022 T4 (Prefijo ENOEN_)\n",
    "    elif 2020 <= year <= 2022:\n",
    "        # 2020 T1 y T2 no tienen datos o son no oficiales (se manejan como \"saltados\" en el script principal)\n",
    "        base_name = f\"ENOEN_SDEMT{quarter}{year_short}\".upper()\n",
    "    \n",
    "    # Periodo 4: 2023 T1 en adelante (Vuelve a May√∫sculas/Patr√≥n consistente con el documento)\n",
    "    else: # year >= 2023\n",
    "        base_name = f\"SDEMT{quarter}{year_short}\".upper()\n",
    "        \n",
    "    dir_name = f\"ENOE_{year}_{quarter}\"\n",
    "    file_name = f\"{base_name}.{file_format}\"\n",
    "    # Asume que los archivos est√°n en data/dta/ENOE_YYYY_Q/SDEMT...\n",
    "    #file_path = os.path.join(\"Data/\", file_format, dir_name, file_name) \n",
    "    file_path = os.path.join(\"Data/ENOE_dta\", dir_name, file_name) \n",
    "    return file_path\n",
    "\n",
    "def pedir_rango_trimestral():\n",
    "    \"\"\"Pide al usuario el rango de a√±os y trimestres para generar la serie de tiempo.\"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            print(\"\\n--- Definici√≥n del Rango de la Serie de Tiempo ---\")\n",
    "            start_year = int(input(\"Ingrese el A√ëO de inicio (e.g., 2018): \"))\n",
    "            start_quarter = int(input(\"Ingrese el TRIMESTRE de inicio (1 a 4): \"))\n",
    "            end_year = int(input(\"Ingrese el A√ëO final (e.g., 2024): \"))\n",
    "            end_quarter = int(input(\"Ingrese el TRIMESTRE final (1 a 4): \"))\n",
    "            \n",
    "            if not (1 <= start_quarter <= 4 and 1 <= end_quarter <= 4):\n",
    "                raise ValueError(\"El trimestre debe ser un n√∫mero entre 1 y 4.\")\n",
    "            \n",
    "            start_date = datetime(start_year, start_quarter * 3 - 2, 1)\n",
    "            end_date = datetime(end_year, end_quarter * 3 - 2, 1)\n",
    "\n",
    "            if start_date > end_date:\n",
    "                raise ValueError(\"El periodo de inicio debe ser anterior o igual al periodo final.\")\n",
    "                \n",
    "            break\n",
    "        except ValueError as e:\n",
    "            print(f\"Entrada inv√°lida: {e}. Por favor, intente de nuevo.\")\n",
    "            \n",
    "    # Generar la secuencia de trimestres\n",
    "    periodos = []\n",
    "    current_year = start_year\n",
    "    current_quarter = start_quarter\n",
    "    \n",
    "    while current_year < end_year or (current_year == end_year and current_quarter <= end_quarter):\n",
    "        \n",
    "        # Manejo de trimestres faltantes (2020 T2 y T3 no oficiales/disponibles)\n",
    "        if current_year == 2020 and current_quarter in [2, 3]:\n",
    "            print(f\"--- ‚ö†Ô∏è Saltando periodo {current_year} T{current_quarter} (No disponible o no oficial). ---\")\n",
    "            pass # No se a√±ade el periodo a la lista para no intentar cargarlo.\n",
    "            \n",
    "        else:\n",
    "            periodos.append((current_year, current_quarter))\n",
    "            \n",
    "        # Pasar al siguiente trimestre\n",
    "        if current_quarter == 4:\n",
    "            current_quarter = 1\n",
    "            current_year += 1\n",
    "        else:\n",
    "            current_quarter += 1\n",
    "            \n",
    "    return periodos\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# FUNCI√ìN PRINCIPAL DE PROCESAMIENTO TRIMESTRAL\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def procesar_trimestre_enoe(year, quarter, file_format='dta'):\n",
    "    \"\"\"\n",
    "    Carga, limpia y calcula indicadores clave a nivel nacional y estatal \n",
    "    para un trimestre espec√≠fico.\n",
    "    \"\"\"\n",
    "    periodo_str = f\"{year} T{quarter}\"\n",
    "    print(f\"\\n--- ‚è≥ Procesando: {periodo_str} ---\")\n",
    "\n",
    "    # --- 1. Obtener Ruta y Ponderador ---\n",
    "    file_path = obtener_nombre_archivo(year, quarter, file_format)\n",
    "    \n",
    "    # Determinar el campo ponderador correcto seg√∫n el periodo \n",
    "    if year < 2020 or (year == 2020 and quarter < 3):\n",
    "        PONDERATOR = 'FAC'\n",
    "    else:\n",
    "        PONDERATOR = 'FAC_TRI'\n",
    "    \n",
    "    # --- 2. Carga de Datos y Manejo de Errores (Debugging) ---\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"‚ùå Error Cr√≠tico: Archivo no encontrado en: {file_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    try:\n",
    "        if file_format == 'dta':\n",
    "            # Se usa `encoding='latin-1'` si se encuentran problemas con codificaci√≥n de texto\n",
    "            df = pd.read_stata(file_path, convert_categoricals=False) \n",
    "        elif file_format == 'csv':\n",
    "            df = pd.read_csv(file_path)\n",
    "        else:\n",
    "            raise ValueError(\"Formato de archivo no soportado.\")\n",
    "        \n",
    "        if df.empty:\n",
    "            print(f\"‚ùå Error de Carga: Archivo encontrado, pero vac√≠o: {file_path}\")\n",
    "            return None, None\n",
    "            \n",
    "        print(f\"‚úÖ Archivo cargado exitosamente. {len(df):,} registros. Ponderador: {PONDERATOR}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Ocurri√≥ un error de lectura de datos en {file_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # --- 3. Limpieza y Preparaci√≥n de Datos ---\n",
    "    \n",
    "    # Conversi√≥n de tipos de datos esenciales y estandarizaci√≥n de nombres\n",
    "    columnas_requeridas = [\n",
    "        PONDERATOR, 'sex', 'eda', 'clase1', 'clase2', 'c_res', 'r_def', 'ent',\n",
    "        'ingocup', 'ing_x_hrs', 'pos_ocu', 'emp_ppal', 'sub_o' # Indicadores estrat√©gicos\n",
    "    ]\n",
    "    \n",
    "    for col in columnas_requeridas:\n",
    "        if col not in df.columns:\n",
    "            # A√±adir columna con NaN/0 si falta, para evitar errores en c√°lculos posteriores (excepto ponderador)\n",
    "            if col == PONDERATOR:\n",
    "                 print(f\"‚ùå Error Cr√≠tico: Columna de ponderador '{PONDERATOR}' no encontrada.\")\n",
    "                 return None, None\n",
    "            df[col] = np.nan if col not in ['r_def', 'c_res'] else 0\n",
    "            print(f\"‚ö†Ô∏è Columna '{col}' no encontrada. Se a√±adi√≥ con NaN/0 para proseguir.\")\n",
    "\n",
    "    # Conversi√≥n de tipos\n",
    "    df['r_def'] = df['r_def'].astype(str).str.strip()\n",
    "    for col in ['sex', 'eda', 'clase1', 'clase2', 'c_res', 'ent', 'pos_ocu', 'emp_ppal', 'sub_o']:\n",
    "         # Convertir a num√©rico, forzando errores a NaN, luego a entero (si es posible)\n",
    "         df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "    for col in ['ingocup', 'ing_x_hrs', PONDERATOR]:\n",
    "         df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "\n",
    "    # CRITERIO GENERAL DE FILTRADO (POBLACI√ìN DE 15 A√ëOS Y M√ÅS)\n",
    "    # R_DEF='00' y (C_RES=1 o 3) y (EDA>=15 y EDA<=98) [cite: 148]\n",
    "    \n",
    "    # 1. Poblaci√≥n total residente\n",
    "    df_base = df[(df['r_def'] == '00') & (df['c_res'].isin([1, 3]))].copy()\n",
    "\n",
    "    # 2. Poblaci√≥n en Edad de Trabajar (PET) 15 a√±os y m√°s\n",
    "    df_15_y_mas = df_base[df_base['eda'].between(15, 98)].copy()\n",
    "    \n",
    "    if df_15_y_mas.empty:\n",
    "        print(\"‚ùå Error de Filtro: No se encontraron registros v√°lidos despu√©s del filtro PET.\")\n",
    "        return None, None\n",
    "    \n",
    "    # Asignaci√≥n de nombres de estado\n",
    "    df_base['ent_nombre'] = df_base['ent'].map(ENTIDADES)\n",
    "    df_15_y_mas['ent_nombre'] = df_15_y_mas['ent'].map(ENTIDADES)\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # --- 4. C√ÅLCULOS A NIVEL NACIONAL ---\n",
    "    # ------------------------------------------------------------------\n",
    "    \n",
    "    # Subconjuntos basados en campos precodificados y el criterio general [cite: 147]\n",
    "    df_pea = df_15_y_mas[df_15_y_mas['clase1'] == 1].copy()      \n",
    "    df_pnea = df_15_y_mas[df_15_y_mas['clase1'] == 2].copy()\n",
    "    df_ocupada = df_15_y_mas[df_15_y_mas['clase2'] == 1].copy() \n",
    "\n",
    "    datos_nacional = {\n",
    "        # Identificadores de Tiempo\n",
    "        'year': year,\n",
    "        'quarter': quarter,\n",
    "        \n",
    "        # 1. Poblaci√≥n\n",
    "        'pob_total': df_base[PONDERATOR].sum(),\n",
    "        'pob_15_y_mas': df_15_y_mas[PONDERATOR].sum(), # [cite: 162]\n",
    "        'pob_hombres_total': df_base[df_base['sex'] == 1][PONDERATOR].sum(),\n",
    "        'pob_mujeres_total': df_base[df_base['sex'] == 2][PONDERATOR].sum(),\n",
    "        \n",
    "        # 2. PEA y PNEA\n",
    "        'pea_total': df_pea[PONDERATOR].sum(),\n",
    "        'pea_hombres': df_pea[df_pea['sex'] == 1][PONDERATOR].sum(),\n",
    "        'pea_mujeres': df_pea[df_pea['sex'] == 2][PONDERATOR].sum(),\n",
    "        'pnea_total': df_pnea[PONDERATOR].sum(), # [cite: 163]\n",
    "        \n",
    "        # Indicadores Estrat√©gicos (CLASE2 y CLASE1) [cite: 162, 163]\n",
    "        'ocupada_total': df_ocupada[PONDERATOR].sum(),\n",
    "        'desocupada_total': df_15_y_mas[df_15_y_mas['clase2'] == 2][PONDERATOR].sum(),\n",
    "        'pnea_disponible': df_15_y_mas[df_15_y_mas['clase2'] == 3][PONDERATOR].sum(),\n",
    "        'pnea_no_disponible': df_15_y_mas[df_15_y_mas['clase2'] == 4][PONDERATOR].sum(),\n",
    "        \n",
    "        # Indicadores Estrat√©gicos (POSICI√ìN EN LA OCUPACI√ìN - Ocupados) [cite: 163]\n",
    "        'subordinados_remunerados': df_ocupada[df_ocupada['pos_ocu'] == 1][PONDERATOR].sum(),\n",
    "        'empleadores': df_ocupada[df_ocupada['pos_ocu'] == 2][PONDERATOR].sum(),\n",
    "        'cuenta_propia': df_ocupada[df_ocupada['pos_ocu'] == 3][PONDERATOR].sum(),\n",
    "        'trabajadores_no_remunerados': df_ocupada[df_ocupada['pos_ocu'] == 4][PONDERATOR].sum(),\n",
    "        \n",
    "        # Indicadores Estrat√©gicos (CONDICI√ìN DE INFORMALIDAD - Ocupados) [cite: 169]\n",
    "        'ocupacion_formal': df_ocupada[df_ocupada['emp_ppal'] == 2][PONDERATOR].sum(),\n",
    "        'ocupacion_informal': df_ocupada[df_ocupada['emp_ppal'] == 1][PONDERATOR].sum(),\n",
    "        \n",
    "        # Indicador Estrat√©gico (SUBOCUPACI√ìN - Ocupados)\n",
    "        'subocupacion': df_ocupada[df_ocupada['sub_o'] == 1][PONDERATOR].sum(),\n",
    "        \n",
    "        # 3. Ingreso Promedio\n",
    "        'ing_prom_mes_total': weighted_average(df_ocupada, 'ingocup', PONDERATOR),\n",
    "        'ing_prom_hora_total': weighted_average(df_ocupada, 'ing_x_hrs', PONDERATOR),\n",
    "    }\n",
    "    \n",
    "    # ------------------------------------------------------------------\n",
    "    # --- 5. C√ÅLCULOS A NIVEL ESTATAL ---\n",
    "    # ------------------------------------------------------------------\n",
    "    \n",
    "    datos_estatal = defaultdict(list)\n",
    "    \n",
    "    for ent_code, ent_name in ENTIDADES.items():\n",
    "        # Filtros base por Estado (Criterio General)\n",
    "        df_base_est = df_base[df_base['ent'] == ent_code].copy()\n",
    "        df_15_y_mas_est = df_15_y_mas[df_15_y_mas['ent'] == ent_code].copy()\n",
    "        \n",
    "        # Subconjuntos Estatales (basados en precodificados y el filtro base estatal)\n",
    "        df_pea_est = df_15_y_mas_est[df_15_y_mas_est['clase1'] == 1].copy()\n",
    "        df_pnea_est = df_15_y_mas_est[df_15_y_mas_est['clase1'] == 2].copy()\n",
    "        df_ocupada_est = df_15_y_mas_est[df_15_y_mas_est['clase2'] == 1].copy()\n",
    "        \n",
    "        # Recolecci√≥n de datos\n",
    "        datos_estatal['year'].append(year)\n",
    "        datos_estatal['quarter'].append(quarter)\n",
    "        datos_estatal['ent_code'].append(ent_code)\n",
    "        datos_estatal['ent_nombre'].append(ent_name)\n",
    "        \n",
    "        # Poblaci√≥n\n",
    "        datos_estatal['pob_total'].append(df_base_est[PONDERATOR].sum())\n",
    "        datos_estatal['pob_15_y_mas'].append(df_15_y_mas_est[PONDERATOR].sum())\n",
    "        datos_estatal['pob_hombres_total'].append(df_base_est[df_base_est['sex'] == 1][PONDERATOR].sum())\n",
    "        datos_estatal['pob_mujeres_total'].append(df_base_est[df_base_est['sex'] == 2][PONDERATOR].sum())\n",
    "        \n",
    "        # PEA y PNEA\n",
    "        datos_estatal['pea_total'].append(df_pea_est[PONDERATOR].sum())\n",
    "        datos_estatal['pnea_total'].append(df_pnea_est[PONDERATOR].sum())\n",
    "        \n",
    "        # Indicadores Estrat√©gicos (CLASE2 y CLASE1)\n",
    "        datos_estatal['ocupada_total'].append(df_ocupada_est[PONDERATOR].sum())\n",
    "        datos_estatal['desocupada_total'].append(df_15_y_mas_est[df_15_y_mas_est['clase2'] == 2][PONDERATOR].sum())\n",
    "        datos_estatal['pnea_disponible'].append(df_15_y_mas_est[df_15_y_mas_est['clase2'] == 3][PONDERATOR].sum())\n",
    "        datos_estatal['pnea_no_disponible'].append(df_15_y_mas_est[df_15_y_mas_est['clase2'] == 4][PONDERATOR].sum())\n",
    "        \n",
    "        # Indicadores Estrat√©gicos (POSICI√ìN EN LA OCUPACI√ìN - Ocupados)\n",
    "        datos_estatal['subordinados_remunerados'].append(df_ocupada_est[df_ocupada_est['pos_ocu'] == 1][PONDERATOR].sum())\n",
    "        datos_estatal['empleadores'].append(df_ocupada_est[df_ocupada_est['pos_ocu'] == 2][PONDERATOR].sum())\n",
    "        datos_estatal['cuenta_propia'].append(df_ocupada_est[df_ocupada_est['pos_ocu'] == 3][PONDERATOR].sum())\n",
    "        datos_estatal['trabajadores_no_remunerados'].append(df_ocupada_est[df_ocupada_est['pos_ocu'] == 4][PONDERATOR].sum())\n",
    "\n",
    "        # Indicadores Estrat√©gicos (CONDICI√ìN DE INFORMALIDAD - Ocupados)\n",
    "        datos_estatal['ocupacion_formal'].append(df_ocupada_est[df_ocupada_est['emp_ppal'] == 2][PONDERATOR].sum())\n",
    "        datos_estatal['ocupacion_informal'].append(df_ocupada_est[df_ocupada_est['emp_ppal'] == 1][PONDERATOR].sum())\n",
    "        \n",
    "        # Indicador Estrat√©gico (SUBOCUPACI√ìN - Ocupados)\n",
    "        datos_estatal['subocupacion'].append(df_ocupada_est[df_ocupada_est['sub_o'] == 1][PONDERATOR].sum())\n",
    "\n",
    "        # Ingreso Promedio\n",
    "        datos_estatal['ing_prom_mes_total'].append(weighted_average(df_ocupada_est, 'ingocup', PONDERATOR))\n",
    "        datos_estatal['ing_prom_hora_total'].append(weighted_average(df_ocupada_est, 'ing_x_hrs', PONDERATOR))\n",
    "\n",
    "    df_estatal_trimestre = pd.DataFrame(datos_estatal)\n",
    "    \n",
    "    return pd.Series(datos_nacional), df_estatal_trimestre\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# EJECUCI√ìN DEL SCRIPT Y CONSOLIDACI√ìN DE SERIES DE TIEMPO\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    periodos = pedir_rango_trimestral()\n",
    "    \n",
    "    # Inicializaci√≥n para la consolidaci√≥n\n",
    "    resultados_nacionales = []\n",
    "    resultados_estatales = []\n",
    "\n",
    "    print(f\"\\n===========================================================\")\n",
    "    print(f\"  INICIANDO PROCESAMIENTO DE {len(periodos)} TRIMESTRES\")\n",
    "    print(f\"===========================================================\")\n",
    "\n",
    "    # Bucle principal para procesar cada trimestre\n",
    "    for year, quarter in periodos:\n",
    "        \n",
    "        df_nacional, df_estatal = procesar_trimestre_enoe(year, quarter)\n",
    "        \n",
    "        if df_nacional is not None and df_estatal is not None:\n",
    "            resultados_nacionales.append(df_nacional)\n",
    "            resultados_estatales.append(df_estatal)\n",
    "        else:\n",
    "            # Manejo expl√≠cito de trimestres sin datos (se a√±ade una fila con NA)\n",
    "            # Esto se asegura de mantener la continuidad de la serie de tiempo.\n",
    "            periodo_na = {'year': year, 'quarter': quarter}\n",
    "            \n",
    "            # Serie Nacional con NA\n",
    "            serie_na_nacional = pd.Series(periodo_na)\n",
    "            # Se a√±aden las columnas faltantes (variables calculadas) con NaN\n",
    "            if resultados_nacionales:\n",
    "                # Usar la estructura de la primera serie de tiempo para rellenar los NaNs\n",
    "                for col in resultados_nacionales[0].index:\n",
    "                    if col not in serie_na_nacional:\n",
    "                         serie_na_nacional[col] = np.nan\n",
    "            resultados_nacionales.append(serie_na_nacional)\n",
    "            \n",
    "            # DataFrame Estatal con NA\n",
    "            df_na_estatal = pd.DataFrame(periodo_na, index=range(1, 33)) # 32 estados\n",
    "            df_na_estatal['ent_code'] = df_na_estatal.index\n",
    "            df_na_estatal['ent_nombre'] = df_na_estatal['ent_code'].map(ENTIDADES)\n",
    "            # Rellenar todas las columnas de variables con NaN\n",
    "            if resultados_estatales:\n",
    "                 # Usar la estructura del primer DataFrame estatal para rellenar los NaNs\n",
    "                for col in resultados_estatales[0].columns:\n",
    "                    if col not in df_na_estatal.columns:\n",
    "                        df_na_estatal[col] = np.nan\n",
    "            resultados_estatales.append(df_na_estatal)\n",
    "            \n",
    "            print(f\"--- üö´ Se agreg√≥ NA/NaN para {year} T{quarter} y se prosigue. ---\")\n",
    "            \n",
    "\n",
    "    # --- 6. CONSOLIDACI√ìN DE BASES DE DATOS ---\n",
    "\n",
    "    # 1. Serie de Tiempo Nacional\n",
    "    df_serie_nacional = pd.DataFrame(resultados_nacionales).reset_index(drop=True)\n",
    "    df_serie_nacional['periodo'] = df_serie_nacional['year'].astype(str) + '-T' + df_serie_nacional['quarter'].astype(str)\n",
    "    df_serie_nacional.set_index('periodo', inplace=True)\n",
    "\n",
    "    print(\"\\n===========================================================\")\n",
    "    print(\"      ‚úÖ BASE DE SERIE DE TIEMPO NACIONAL CREADA\")\n",
    "    print(\"      (Incluye nuevos indicadores estrat√©gicos)\")\n",
    "    print(\"===========================================================\")\n",
    "    print(df_serie_nacional.head())\n",
    "    # Opcional: df_serie_nacional.to_csv(\"serie_tiempo_nacional_estrat.csv\")\n",
    "\n",
    "\n",
    "    # 2. Serie de Tiempo Estatal\n",
    "    df_serie_estatal = pd.concat(resultados_estatales, ignore_index=True)\n",
    "    df_serie_estatal['periodo'] = df_serie_estatal['year'].astype(str) + '-T' + df_serie_estatal['quarter'].astype(str)\n",
    "    \n",
    "    print(\"\\n===========================================================\")\n",
    "    print(\"      ‚úÖ BASE DE SERIE DE TIEMPO ESTATAL CREADA\")\n",
    "    print(\"      (Incluye nuevos indicadores estrat√©gicos)\")\n",
    "    print(\"===========================================================\")\n",
    "    print(df_serie_estatal.head())\n",
    "    # Opcional: df_serie_estatal.to_csv(\"serie_tiempo_estatal_estrat.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
